\documentclass[acmsmall,nonacm]{acmart}

% Ensure the non-ACM draft compiles cleanly under acmart without conference metadata.
\settopmatter{printacmref=false,printccs=false,printfolios=true}
\renewcommand\footnotetextcopyrightpermission[1]{}
\acmConference[]{}{}{}
\acmBooktitle{}
\acmYear{}
\copyrightyear{}

% ---------- Space saving, etc ----------
\usepackage{microtype}
\usepackage{enumitem}
\usepackage{etoolbox}

\makeatletter
\pretocmd{\@begintheorem}{\setlength{\topsep}{2pt}}{}{}
\pretocmd{\@endtheorem}{\setlength{\topsep}{2pt}}{}{}
\makeatother

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
  {-0.5ex \@plus -0.2ex \@minus -0.2ex}%
  {-0.8em}%
  {\normalfont\normalsize\itshape}}
\makeatother


% ---------- Theorem environments ----------
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\theoremstyle{remark}
\newtheorem{remark}{Remark}
% \newtheorem{example}{Example}

% \usepackage{mdframed}
% \newmdtheoremenv{example}{Example}

% \newtheorem{exampleinner}{Example}
% \newcommand{\exampleend}{\hfill$\diamond$}
% \newenvironment{example}
%   {\begin{exampleinner}}
%   {\exampleend\end{exampleinner}}

\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{amsthm}

% Define a very light gray
\definecolor{examplegray}{gray}{0.85}

\newtheorem{exampleinner}{Example}

\newmdenv[
  linecolor=examplegray,
  linewidth=0.6pt,
  roundcorner=3pt,
  innertopmargin=0.6\baselineskip,
  innerbottommargin=0.6\baselineskip,
  innerleftmargin=1em,
  innerrightmargin=1em,
  skipabove=\baselineskip,
  skipbelow=\baselineskip,
]{exampleframe}

\newenvironment{example}
  {\begin{exampleframe}\begin{exampleinner}}
  {\end{exampleinner}\end{exampleframe}}

% ---------- Macros ----------
\newcommand{\Hist}{\mathcal{H}}
\newcommand{\Poss}{\mathsf{Poss}}
\newcommand{\Spec}{\mathsf{Spec}}
\newcommand{\SpecIt}{\mathsf{\mathit{Spec}}}
\newcommand{\Obs}{\mathsf{Obs}}
\newcommand{\Ord}{\preceq}
\newcommand{\hext}{\sqsubseteq_h}
\newcommand{\In}{\mathsf{In}}
\newcommand{\Expose}{\mathsf{Expose}}

% ---------- Comments ----------
\newcommand{\jmh}[1]{\textcolor{red}{[JMH: #1]}}

% Notation conventions (for internal reference):
% - Histories: \Hist is the set of histories; elements are H, H_1, H_2.
% - Happens-before: e_1 \rightarrow e_2 is Lamport's relation on events.
% - History extension: H_1 \hext H_2 is the history-extension order.
% - Observation function: \Poss : \Hist \to 2^O.
% - Specification: \Spec = (\Poss, \Ord, \Obs).
% - Admissibility: \Obs : \Hist \to 2^O.
% - Outcome order: o_1 \Ord o_2 means o_2 does not contradict o_1.
% - Processes/events/outcomes: p, q (processes), e, e\' (events), o, o\' (outcomes).
\begin{document}

% ================================================================
% Note (meta): Before submission, check the PODC page limit and trim
% Applications/Related Work as needed.
% Note (meta): Ensure all claims of generalization over CALM/CAP/hierarchy have
% precise statements and proofs or citations.
\begin{abstract}
  When is coordination \emph{intrinsically required} by a distributed specification,
  rather than imposed by a particular protocol or implementation strategy?
  We give a general answer using minimal assumptions.
  In an asynchronous message-passing model, we show that a specification
  admits a coordination-free implementation if and only if it is monotone with
  respect to history extension under an appropriate order on observable outcomes.

  This \emph{Coordination Criterion} is stated directly over Lamport histories and
  specification-level observations, without assuming any particular programming
  language, object implementation, or protocol structure.
  It yields a sharp boundary between specifications that can be implemented without
  coordination and those for which coordination is unavoidable.
  The criterion provides a uniform explanation for a range of classical results,
  including CAP-style impossibility results, CALM-style coordination-freedom,
  agreement tasks, snapshots, transactional isolation, and invariant confluence,
  all as instances of the same underlying semantic phenomenon.
\end{abstract}


\title{The Coordination Criterion}
\author{Joseph M. Hellerstein}
\affiliation{%
  \institution{UC Berkeley \& Amazon Web Services}
  \city{Berkeley, CA}
  \country{USA}
}
\date{}
\maketitle



% ================================================================
\section{Introduction}
\label{sec:introduction}
% ================================================================

% Coordination is a recurring theme in distributed computing.
% Protocols such as agreement, atomic commit, synchronous barriers, and termination
% detection are widely used to ensure correct behavior under asynchrony and
% partial failure.
% At the same time, coordination is costly: it introduces latency, complexity,
% and sensitivity to failures.
% This motivates a fundamental question:

% \begin{quote}
%   When is coordination \emph{intrinsically necessary} to implement a distributed
%   specification?
% \end{quote}

% The relationship between specification-level correctness requirements and
% concrete coordination mechanisms has been explored in several lines of work.
% In the CAP theorem~\cite{gilbert2002cap}, coordination appears as the loss of
% availability required to maintain strong consistency under partitions, while
% the CALM principle~\cite{hellerstein2010declarative} connects coordination-freedom to
% monotonicity in declarative programs.
% Distributed computability theory similarly characterizes which tasks require
% waiting or stronger primitives, most notably via object- and task-based
% hierarchies such as consensus numbers~\cite{herlihy1991waitfree,herlihy1999topological}.
% Each of these approaches isolates important aspects of coordination, but does so
% under specific modeling assumptions and for particular classes of specifications.

% What is missing is a general semantic account that explains coordination
% \emph{as a property of the specification itself}, independent of programming
% model, protocol structure, or particular consistency conditions.
% Equivalently, we would like a single semantic boundary theorem that says
% exactly when coordination is intrinsically required by a specification across
% different models and implementation techniques.
% Our Coordination Criterion provides such a sharp boundary theorem: it identifies a
% monotonicity condition on specifications that is necessary and sufficient for
% coordination-freedom. Because the criterion is phrased directly over observable
% outcomes and histories, it applies uniformly across distributed objects,
% agreement tasks, consistency models, and even optimization problems, with CALM-
% and CAP-style results arising as special cases.

% % MOVE TO RELATED WORK SECTION (WHERE)
% Historically, results on coordination in distributed systems have been developed
% at different levels of abstraction, from low-level read/write objects and
% consistency conditions to higher-level program and problem semantics.
% Insights at one level have not always transferred cleanly to others.
% By formulating coordination as a semantic property of specifications over
% histories and observable outcomes, our framework is agnostic to
% this choice of level, allowing coordination requirements to be analyzed
% uniformly across classical object-level semantics and higher-level formulations.

% Conceptually, the key to our results is to shift the focus from monotonicity
% of input semantics (e.g., a query or update operator in a particular
% programming model, as in CALM) to monotonicity of the specification map
% with respect to an outcome order on observable outcomes.
% Once we choose an observation function and outcome order, our criterion asks
% only whether the induced specification $\Spec = (\Poss, \Ord, \Obs)$ is
% monotone under history extension; any particular programming model then
% appears merely as an implementation vehicle for realizing such monotone
% specifications.

% \paragraph{Contribution.}
% We identify a general semantic boundary between
% distributed specifications that admit coordination-free implementations and
% those that do not.
% Our contributions are as follows:
% \begin{itemize}[nosep]
%   \item \textbf{Semantic framework.} We formalize a minimalist, general semantic model
%         for distributed specifications based on asynchronous histories, an
%         observation function, and an outcome order capturing non-contradiction
%         (Section~\ref{sec:obs-consistency}).
%   \item \textbf{Coordination Criterion.} We prove that a specification admits a
%         coordination-free consistent implementation if and only if it is monotone
%         with respect to history extension under the chosen outcome order (our main
%         theorem).
%   \item \textbf{Semantic grounding of classical results.} We instantiate the
%         framework to semantically explain, and in some cases recover as direct
%         corollaries, a range of
%         classical results about CAP/linearizability, snapshots, agreement tasks,
%         transactional isolation levels, and invariant confluence
%         (Section~\ref{sec:applications} and Appendix~\ref{sec:additional-applications}).
% \end{itemize}

% Our focus in this paper is on safety-style semantic conditions on observable
% behaviors—what we will broadly call \emph{consistency} in
% Section~\ref{sec:obs-consistency}—not liveness.
% As such, the Coordination Criterion characterizes when a specification admits a
% coordination-free implementation whose observable behaviors satisfy a given
% consistency requirement under all admissible asynchronous executions, including
% executions with failures such as message loss, delay, and process crashes.
% It is deliberately agnostic about progress guarantees such as termination or
% wait-freedom, as well as the details of failure-recovery mechanisms, which are
% orthogonal to the semantic questions studied here.
% Accordingly, the Coordination Criterion focuses on when coordination is
% semantically unavoidable, not on how non-monotonicity is resolved or how
% progress is ensured.

% Throughout, specifications in our framework are compositional and need not
% correspond to entire distributed services.
% They may describe the behavior of components, interfaces, or subroutines
% within a larger system, allowing the Coordination Criterion to be applied
% at multiple levels of specification.
% The typical question is not whether an entire system uses coordination at all, but
% which parts of its logic intrinsically require coordination and which
% provably do not.

% To make the discussion concrete, we will occasionally refer to a simple
% running example: a single read--write register replicated at two processes
% in an asynchronous message-passing system.
% We will consider two specifications for this object over the same
% computational model and observations: a highly available, eventually
% consistent register and a linearizable register.
% Throughout the paper we use this example to illustrate how choices of
% observation, outcome order, and specification determine whether
% coordination is semantically necessary.

Coordination is a recurring theme in distributed computing.
Protocols such as agreement, atomic commit, and synchronous barriers are widely
used to ensure correctness under asynchrony and partial failure.
At the same time, coordination is costly: it introduces latency, complexity, and
sensitivity to failures.
This motivates a fundamental question:

\begin{quote}
  When is coordination \emph{intrinsically necessary} to implement a distributed
  specification?
\end{quote}

Prior work has approached this question from many angles and levels of
abstraction.
At the level of mechanisms and protocols, classical impossibility and hierarchy
results for consensus and atomic commitment characterize when processes must
wait, synchronize, or rely on stronger primitives.
At the level of shared objects and consistency, the CAP theorem relates
coordination to availability under partitions for strong guarantees such as
linearizability.
At the level of programs and applications, the CALM theorem and its successors
connect coordination-freedom to monotonicity of observable behavior.
Transactional isolation and invariant-preserving replication introduce another
perspective, reasoning about coordination through anomalies and
application-level correctness.

These results capture essential facets of coordination, but they are developed
within formalisms tailored to particular mechanisms, consistency models, or
programming abstractions.
This paper instead characterizes when coordination is \emph{intrinsically required}
across this spectrum.

We show that coordination is not an artifact of particular protocols, languages,
or consistency conditions, but a property of a specification itself.
By formulating specifications directly over Lamport histories and a
specification-defined notion of observability, we obtain a sharp boundary
theorem—the \emph{Coordination Criterion}—that applies across settings.

The Coordination Criterion states that \emph{a specification admits a
  coordination-free implementation if and only if it is monotone with respect to
  history extension}. This formulation subsumes settings previously studied in isolation:
CAP-style impossibility results, CALM-style coordination-freedom results,
classical distributed protocols, and programming language analyses all emerge as
instances of a single underlying phenomenon.
By remaining agnostic to abstraction level—objects, programs, or tasks—the
criterion explains when coordination is necessary and when it is not.

The payoff of this formulation is not merely unifying, but diagnostic.
When the criterion fails, coordination cannot be eliminated by alternative
protocol designs; when it holds, coordination-free implementations exist.
This allows coordination requirements to be understood \emph{before} algorithm
design begins, and across settings where prior results had to be established
separately.

\paragraph{Scope.}
This paper focuses on safety-style semantic conditions on observable behaviors,
which we broadly refer to as \emph{consistency}.
The Coordination Criterion characterizes when a specification admits a
coordination-free implementation under all admissible asynchronous executions,
including executions with message delay, loss, and crashes.
We deliberately abstract away from liveness concerns such as termination or
wait-freedom, and from failure-recovery mechanisms, which are orthogonal to the
semantic necessity of coordination.
Our goal is to identify when coordination is intrinsically required by a
specification.

\subsection{Coordination, Consistency, and Monotonicity: Core Intuitions}

Our discussion rests on three related semantic concepts—coordination,
consistency, and monotonicity—which we summarize informally here to
orient the formal development that follows.

\paragraph{Coordination.}
We treat coordination as a semantic phenomenon rather than a protocol mechanism.
Intuitively, coordination arises when correctness requires an implementation to
\emph{exclude causally possible behaviors}.
In an asynchronous system, many different events may be causally enabled at a
given point.
An implementation is coordination-free when it allows all such
extensions to history.

\paragraph{Consistency.}
In our setting, consistency is a \emph{no-regret property of observations}:
an observation based on partial information (e.g., a history prefix or
network partition) is consistent if every subsequent causal extension of the
history has at least one outcome that remains within the specification.
This minimalist notion captures the semantic core of familiar
reconciliation-based models of consistency, isolating just what is needed to determine if coordination is intrinsically unavoidable.

\paragraph{Monotonicity.}
Monotonicity concerns how observations evolve as histories are extended, and whether
later observations can become inconsistent with earlier ones.
We capture this by relating history extension to a partial order on outcomes:
extending a history should move observations \emph{upward} in the outcome order,
preserving consistency
(e.g., adding facts to a set, increasing a count).

\medskip
Our main result characterizes coordination-freedom in terms of monotonicity.
A specification admits a coordination-free implementation exactly when it is
monotone: observable outcomes remain consistent under all history extensions.
When monotonicity fails, consistency cannot be preserved across all causal
extensions, forcing coordination: the exclusion of admissible histories.


% ================================================================
\section{Computational Model}
% ================================================================
We model executions as Lamport histories: finite or infinite partially ordered sets of events ordered by happens-before (i.e., event structures, not linear traces).

\begin{definition}[History]
  \label{def:history}
  A \emph{history} \(H = (E,\rightarrow)\) is a finite or infinite partially
  ordered set of events, ordered by Lamport’s happens-before relation~\cite{lamport1978time}.
  We write $\Hist$ for the class of all histories.
  The happens-before relation is the least partial order induced by:
  \begin{itemize}[nosep]
    \item local program order at each process, and
    \item message causality, where each receive event is preceded by its matching send.
  \end{itemize}
  Events include external input events, local state transitions, and message send
  and receive events.
\end{definition}

Crucially, happens-before is descriptive rather than operational:
it records causal constraints induced by events in an execution, not a
coordination mechanism or a design choice imposed by a specification.
Moreover, \emph{histories in our model need not be complete.}
A history may represent an execution prefix with pending operations,
in-flight messages, or unresolved outcomes.
Unlike transaction schedules or completed traces, histories do not exclude
in-progress activity.
They are evolving objects, which may be extended by additional
events consistent with causality.

External input events represent activity at the system interface, prior to any
semantic interpretation by a specification.
We isolate them to compare executions that receive the same inputs but differ in
asynchronous scheduling.
\begin{definition}[Input history of an execution]
  For any history $H=(E,\rightarrow)$, let $E_{\mathit{in}}(H)\subseteq E$ be the
  set of \emph{input events} in $H$. Define the \emph{input history}
  $\In(H) \triangleq
    \bigl(E_{\mathit{in}}(H),\ \rightarrow \cap (E_{\mathit{in}}(H)\times E_{\mathit{in}}(H))\bigr)$.
\end{definition}

Histories record only events that actually occur in an execution; they do not
describe events that might occur in alternative extensions.
We do not introduce explicit crash or recovery events: a crash corresponds to a
prefix after which a process performs no further events.
Messages may be delayed, reordered, or never delivered; a send without a matching
receive denotes a lost or indefinitely delayed message.
We impose no fairness or progress assumptions: enabled events need not occur, and
messages need not be delivered.
Unless stated otherwise, liveness properties such as termination or wait-freedom
are treated separately from the safety-style semantic conditions studied here.

\begin{definition}[History Extension]
  For histories \(H_1 = (E_1,\rightarrow_1)\) and \(H_2 = (E_2,\rightarrow_2)\),
  we write \(H_1 \hext H_2\) if:
  \begin{itemize}[nosep]
    \item \(E_1 \subseteq E_2\),
    \item \(\rightarrow_1 = \rightarrow_2 \cap (E_1 \times E_1)\), and
    \item $E_1$ is downward closed under $\rightarrow_2$, i.e., for every
          $e \in E_1$, if $e' \rightarrow_2 e$ then $e' \in E_1$.  \end{itemize}
\end{definition}
History extension preserves all previously observed events and causal relations
and adds only causally later events.

% \paragraph{Example (replicated register).}
% Consider a history \(H_1\) in which process \(p\) performs a write and sends a
% message to process \(q\), but the message has not yet been delivered.
% An extension \(H_2\) of \(H_1\) may add the corresponding receive event at \(q\),
% or may add other local events at either process, so long as all happens-before
% constraints are respected.
% Crucially, \(H_2\) cannot remove or reorder events already in \(H_1\), nor can it
% introduce new causal predecessors of existing events.

% ================================================================
\section{Possibilities, Observations, Ordering and Consistency}
\label{sec:obs-consistency}
% ================================================================

We begin with a simple example that motivates the distinction between what may
still occur in the future of an execution and what a specification is willing to
treat as correct at a given point in time.

\begin{example}[Possibility versus observability]
  \label{ex:counter-poss-obs}
  Consider a specification whose outcomes record the value of a monotonically
  increasing counter.
  At a history $H$ in which two increment events have occurred, future executions
  may perform additional increments.
  Accordingly, what's possible is
  $
    \Poss(H) = \{2,3,4,\ldots\}.
  $
  The specification may nevertheless define only the current value to be
  observable at $H$, so what's observable is only
  $
    \Obs(H) = \{2\}.
  $
  Larger values remain possible in future extensions of the history, but are not
  yet observable at $H$ itself.
  This distinction—between outcomes that remain possible in future extensions of a
  history and outcomes that are observable at the present—is central to our
  framework.
\end{example}


\begin{definition}[Possibility Function]
  A \emph{possibility function} is a function
  $
    \Poss : \Hist \rightarrow \mathcal{P}(O),
  $
  where \(O\) is a set of outcomes.
  Intuitively, \(\Poss(H)\) is the set of outcomes that may still occur in some
  execution extending history \(H\).
\end{definition}

One might expect a specification to be defined directly by the set of causal
extensions admissible from each history.
However, for our purposes we abstract away from individual executions.
Two histories are equivalent when they induce the same observable outcomes.
The possibility function $\Poss$ is the induced abstraction that records, for each
history $H$, which outcomes are realized by \emph{some} admissible extension.
Making admissible history extensions explicit would not change our results, but
would complicate the presentation without adding semantic insight.

Possibility is therefore set-valued: $\Poss(H)$ is a set of outcomes rather than a
single outcome.
This reflects that an evolving history may admit multiple distinct
extensions—and hence multiple outcomes—under asynchrony.
The framework does not require that distinct outcomes in $\Poss(H)$ be jointly
realizable in a single execution, nor that they converge to a common future
outcome.

\begin{definition}[Observability Function]
  An \emph{observability function} is a function
  $
    \Obs : \Hist \rightarrow \mathcal{P}(O),
  $
  such that $\Obs(H) \subseteq \Poss(H)$ for all histories $H$.
\end{definition}

While $\Poss(H)$ characterizes which outcomes may still occur in future extensions
of a history, $\Obs(H)$ captures which outcomes the specification treats as correct
at history $H$ itself.
This separation allows us to reason explicitly about the relationship between
future behaviors and present semantic commitments.
As we show below, coordination arises precisely when committing to observable
outcomes rules out other outcomes that would otherwise remain possible.

\remark[Silence]
Our framework permits specifications whose observability function remains empty for some histories. Such silence represents the absence of semantic commitment, not a violation of correctness. We return to this design choice in Section~\ref{sec:silence}.

To reason about whether observable outcomes remain valid as histories extend, we
compare outcomes using an order that captures semantic refinement.

\begin{definition}[Outcome Order]
  The outcome domain $O$ is equipped with a partial order $\Ord$, called the
  \emph{outcome order}.
  Intuitively, $o_1 \Ord o_2$ means that $o_2$ is a compatible refinement of $o_1$:
  the commitments represented by $o_1$ remain valid after those represented by
  $o_2$.
\end{definition}
\noindent
The outcome order $\Ord$ does not impose an execution order or a notion of program
state.
Rather, it captures \emph{semantic compatibility under history extension}:
$o_2$ extends $o_1$ exactly when every behavior consistent with $o_2$
also respects the commitments made by $o_1$.
This notion of compatibility lets us define consistency directly at the level of
observable outcomes, without reference to operational mechanisms such as
linearization points, schedules, or traces.

\begin{definition}[Consistency and Contradiction]
  A set of observations $S \subseteq O$ is \emph{consistent} if there exists an
  outcome $o \in O$ such that $s \Ord o$ for all $s \in S$.
  Two outcomes are said to \emph{contradict} if they do not form a
  consistent set.
\end{definition}

Consistency captures a \emph{no-regret} property under asynchrony.
If $o \in \Obs(H)$, then for every extension $H' \hext H$,
there exists $o' \in \Obs(H')$ such that $o \Ord o'$.
When this property fails, every outcome observable at a prefix history is ruled
out by some causally admissible extension—precisely the situation that
necessitates coordination.

Whether a specification can preserve observational consistency under \emph{all}
causally admissible history extensions is the key determinant of
coordination-freedom.
We formalize this requirement as a monotonicity condition on specifications with
respect to the outcome order $\Ord$ in Section~\ref{sec:monotonicity}.

\subsection{Faithful Outcome Modeling}
\label{rem:faithful-observations}
The choices of possibility function $\Poss$, observability function $\Obs$, and
outcome order $\Ord$ are all part of the specification and play central semantic
roles.
Together, they determine which behaviors may still occur, which outcomes are
treated as correct at a given history, and how outcomes relate under history
extension.

Intuitively, $\Poss$ plays the role traditionally occupied by an operational
specification, such as an automaton or program semantics, by defining which
behaviors remain possible after a given history, while abstracting away from how
those behaviors are generated.
The observability function $\Obs$ and outcome order $\Ord$ then restrict this
space of causally possible outcomes, determining which outcomes are treated as
correct and when divergent behaviors are deemed incompatible.

These modeling choices are critical.
If the outcome space or order is too coarse, semantically incompatible behaviors
may be treated as indistinguishable.
For example, if all outcomes are identified as equivalent, or if the outcome
space contains a greatest element $\top$ extending every outcome, then every
observation becomes vacuously compatible with every future behavior.
Conversely, if the order is too fine—so that distinct outcomes admit no common
refinement—then even specifications that intuitively tolerate concurrency may
appear to reach semantic dead ends prematurely.

Faithful modeling requires choosing $(\Poss,\Ord,\Obs)$ so that
observable outcomes contradict exactly when they represent genuinely
incompatible behaviors under the intended specification.
Altering this triple changes the specification itself, not the coordination
requirements of its implementation.

% ================================================================
\section{Specifications and Coordination}
% ================================================================
Specifications in our framework are compositional and need not
correspond to entire distributed services.
They may describe the behavior of components, interfaces, or subroutines
within a larger system, allowing the Coordination Criterion to be applied
at multiple levels of specification.
The typical question is not whether an entire system uses coordination at all, but
which parts of its logic intrinsically require coordination and which
provably do not.

We now bundle the components introduced above into a single semantic object.
\begin{definition}[Specification]
  \label{def:distributed-specification}
  A specification is a triple
  \mbox{$\Spec = (\Poss, \Ord, \Obs)$}, where:
  \begin{itemize}[nosep]
    \item $\Poss : \Hist \to \mathcal{P}(O)$ is the possibility function,
    \item $\Ord$ is a partial order on $O$, called the outcome order, and
    \item $\Obs : \Hist \to \mathcal{P}(O)$ is the observability function, with
          $\Obs(H) \subseteq \Poss(H)$ for all histories $H$.
  \end{itemize}
\end{definition}

\begin{example}[Replicated Register Specifications]
  \label{ex:register-specs}
  Consider histories in
  which processes issue read and write operations on a single logical register
  replicated at two nodes.
  This example illustrates the distinction between outcomes that remain
  \emph{possible} after a history and those that a specification treats as
  \emph{observable} at that history.

  Fix a possibility function $\Poss$ that maps a history to the sequence of
  completed operations annotated with their arguments and return values, and let
  the outcome order $\Ord$ be prefix extension on such sequences.

  We define two specifications
  $\Spec_{\mathit{avail}} = (\Poss, \Ord, \Obs_{\mathit{avail}})$ and
  $\Spec_{\mathit{lin}} = (\Poss, \Ord, \Obs_{\mathit{lin}})$,
  differing only in their observability functions.
  The first, $\Spec_{\mathit{avail}}$, describes a highly available register:
  after history $H$, a read may return the initial value or any value written in
  the causal past of that read.
  The second, $\Spec_{\mathit{lin}}$, describes a linearizable register:
  $\Obs_{\mathit{lin}}(H)$ contains exactly those sequences that admit a
  linearization respecting real time.

  Both specifications share the same histories, possibility function, and outcome
  order; they differ only in which possible outcomes they designate as observable.
\end{example}

\paragraph{Asynchronous Model and Admissible Histories.}
We work in a standard asynchronous message-passing model.
Executions are parameterized by a prefix of external inputs.
For a fixed input history $H_{\mathit{in}}$, the environment determines which
executions are possible by extending $H_{\mathit{in}}$ with additional external inputs
and asynchronous scheduling, including message delay or loss and process crashes,
without imposing fairness or progress assumptions. Throughout, we fix a specification
$\Spec = (\Poss,\Ord,\Obs)$.

\begin{definition}[Implementation]
  An implementation $I$ describes both
  (i) which executions are possible under a given pattern of external inputs and
  (ii) which outcomes it may expose during those executions.
  Formally, $I$ consists of:
  \begin{itemize}[nosep]
    \item for each input history prefix $H_{\mathit{in}}$, a set of realizable
          histories $\mathcal{R}_I(H_{\mathit{in}}) \subseteq \Hist$, and
    \item an outcome-exposure map $\Expose_I : \Hist \to \mathcal{P}(O)$, where
          $\Expose_I(H)$ is the set of outcomes that $I$ may expose at history $H$.
  \end{itemize}
  An implementation is \emph{correct} for $(\Poss, \Ord, \Obs)$ if $\Expose_I(H)\subseteq \Obs(H)$ for all histories $H$.
\end{definition}

\paragraph{Admissible histories.}
Admissibility is defined solely by causality and input history.
For a fixed input history prefix $H_{\mathit{in}}$, the asynchronous model
determines a set of causally admissible executions: all histories that extend
$H_{\mathit{in}}$ and respect Lamport’s happens-before relation.
This set is defined independently of any specification or implementation and
serves as the baseline against which coordination is measured.
The set of admissible histories is upward-closed under history extension.

\begin{definition}[Coordination-Free Implementation]
  Fix a specification \mbox{$\Spec = (\Poss, \Ord, \Obs)$}.
  For any input history prefix $H_{\mathit{in}}$, define the set of
  \emph{admissible histories}
  \[
    \mathcal{A}(H_{\mathit{in}})
    \triangleq
    \{\, H \in \Hist \mid H_{\mathit{in}} \hext \In(H) \,\}.
  \]
  This set represents the executions permitted by asynchrony and causality alone.
  An implementation $I$ is \emph{coordination-free} if, for every input history
  $H_{\mathit{in}}$:
  \begin{enumerate}[nosep]
    \item \emph{(Correctness)}
          For every $H \in \mathcal{R}_I(H_{\mathit{in}})$,
          $\Expose_I(H) \subseteq \Obs(H)$.
    \item \emph{(No additional pruning)}
          $\mathcal{R}_I(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$.
  \end{enumerate}
\end{definition}
\noindent
The no-additional-pruning condition captures the absence of coordination:
a coordination-free implementation excludes no execution permitted by
asynchrony and causality.
% For example, as we will see, the highly available register specification admits
% a coordination-free implementation, while the linearizable specification does not.


\begin{remark}[Coordination vs.\ Nondeterminism]
  A specification may admit multiple outcomes for the same history, and an
  implementation may nondeterministically choose among them.
  Such choice does not constitute coordination in our sense.
  The distinction is not whether, for a fixed history $H$, an implementation selects
  one outcome in $\Obs(H)$ rather than another, but whether it must exclude some \emph{causally admissible
    histories} in order to remain correct.
\end{remark}

\begin{remark}[Coordination vs.\ Protocol Mechanics]
  Communication mechanisms such as acknowledgments, retries, or message reordering
  merely react to events that occur: they add events and causal relations, but do not
  restrict which extensions remain possible.
  By contrast, a mechanism constitutes coordination when its correctness relies on
  \emph{excluding} some of those admissible histories.
\end{remark}

\begin{example}[Observation-Preserving vs. Observation-Restricting Mechanisms]
  Consider a request--response protocol in which a client repeatedly retries a
  request until it receives an acknowledgment.
  Under our asynchronous model, retries preserve the possibility set $\Poss(H)$:
  for any causally consistent execution prefix $H$, the set $\Poss(H)$ is unchanged,
  regardless of whether the server ever responds.
  Crucially, the client’s choice to retry or to wait does not exclude any causally
  admissible history: executions in which the server never responds remain
  admissible, differing only in which observations are exposed.

  By contrast, a barrier requires that no process proceed until all have reported
  completion. This rules out causally admissible histories in which some processes
  continue to act while others have not yet responded—even though such histories
  are permitted by causality.
  Similarly, a quorum protocol excludes executions in which decisions are made
  before responses from a sufficient set of replicas have arrived.

  These excluded histories correspond to executions that \emph{act early}, under
  partial information.
  Such behaviors may be forbidden under a given specification—which is precisely
  why that specification requires coordination to prevent them.
\end{example}

% ================================================================
\section{Monotonicity}
\label{sec:monotonicity}
% ================================================================

\begin{definition}[Monotone Specification]
  A specification $\Spec = (\Poss,\Ord,\Obs)$ is \emph{monotone} if for all histories
  $H_1 \hext H_2$ and all outcomes $o \in \Obs(H_1)$, there exists an outcome
  $o' \in \Obs(H_2)$ such that $o \Ord o'$.
\end{definition}

Monotonicity can be understood as a no-regret condition on observable behavior.
Once an outcome is treated as correct at some history, extending the execution
should not later invalidate that outcome.
When monotonicity does not hold, an outcome that was acceptable at a prefix history
may be invalidated by a causally admissible extension.
Avoiding such regret in non-monotone specifications forces implementations to restrict which executions may occur.
This is exactly why non-monotonic specifications require coordination\footnote{Formally,
  this condition is stronger than monotonicity under the lower
  powerdomain preorder on outcome sets, which would permit outcomes in $\Obs(H)$
  to be discarded so long as some dominating outcome remains.
  Our definition forbids such loss: outcomes observable at a prefix history must
  remain compatible with at least one outcome at every extension.}.

\begin{remark}
  A specification $\Spec$ is defined on all histories, not only on
  complete executions. Thus for any finite prefix history $H$, the set
  $\Obs(H)$ represents the observable outcomes at $H$.
  When $\Spec$ is monotone, extending the execution can only refine these
  possibilities in the outcome order: any outcome in $\Obs(H)$ remains
  compatible with some outcome in $\Obs(H')$ at every extension $H' \hext H$.
  In this sense, monotone specifications give a meaningful and stable semantics
  to early observations, aligning our framework with the standard view of
  safety properties as sets of executions closed under finite
  prefixes~\cite{alpern1985liveness}.
\end{remark}

% ================================================================
\section{The Coordination Criterion}
% ================================================================

We distinguish the causal structure supplied by the environment (happens-before)
from the semantic constraints imposed by a specification on observable outcomes.
The question we now answer is when such semantic constraints on observable outcomes
can be realized without coordination.

\begin{theorem}[Coordination Criterion]\label{thm:coordination-criterion}
  A distributed specification admits a coordination-free
  implementation \emph{iff} it is monotone with respect to history
  extension under the chosen outcome order $\Ord$.
\end{theorem}

\begin{example}[Replicated register revisited]
  Consider the replicated register specifications from
  Example~\ref{ex:register-specs}, with observations taken to be sequences of
  completed operations ordered by prefix extension.
  Let $H_1$ be a history in which a process has invoked a read operation, and
  concurrently another replica has invoked a write of value $1$, but neither
  operation has yet completed.
  At this prefix, the outcome
  $
    o = \langle \mathsf{read}(0) \rangle
  $
  lies in both $\Obs_{\mathit{avail}}(H_1)$ and $\Obs_{\mathit{lin}}(H_1)$,
  corresponding to completing the read before observing the write.

  Now extend $H_1$ to a history $H_2$ in which the write is delivered and completed
  before the read completes.
  Under $\Spec_{\mathit{avail}}$, the earlier outcome $o$ remains compatible with
  $H_2$, since reads may ignore concurrent writes.
  Under $\Spec_{\mathit{lin}}$, however, every outcome in $\Obs_{\mathit{lin}}(H_2)$
  requires the read to return $1$, and no such outcome extends $o$ under $\Ord$.

  Thus $\Spec_{\mathit{lin}}$ is non-monotone with respect to history extension,
  and $\Spec_{\mathit{avail}}$ is monotone.
  This pinpoints the semantic source of coordination: linearizability treats a read
  return value as observable at a prefix history that cannot be extended along all
  admissible continuations.
\end{example}

\subsection{Proof Sketch}
We prove the theorem in the asynchronous message-passing model of
Section~\ref{sec:obs-consistency}, with finite or infinite histories, unbounded
message delay or loss, and crash failures modeled as processes that take no
further steps; no progress or fairness assumptions are made.

We sketch the argument here; a full proof, including an explicit operational
construction, appears in Appendix~\ref{app:coordination-criterion-proof}.

In this proof sketch,
% we write $\Expose_I(H)\subseteq O$ for the set of outcomes
% exposed by implementation $I$ at history $H$, and 
we require
correctness of implementations: $\Expose_I(H)\subseteq \Obs(H)$.

\paragraph{Sufficiency.}
For the ``if'' direction, we exhibit an idealized implementation $I_\Spec$ that
realizes all causally consistent extensions of any admissible input history.
At each history $H$, the implementation may expose any outcome
$o \in \Obs(H)$, i.e., choose $\Expose_I(H)=\{o\}$, but crucially it makes no
commitment to that choice:
observations do not restrict future behavior.

Because $\Spec$ is monotone, every outcome in $\Obs(H)$ remains
compatible with at least one outcome in $\Obs(H')$ at every extension
$H' \hext H$.
Thus, regardless of which observation is reported at $H$, the implementation
can continue to report correct observations along all causally consistent
extensions.
Consequently, $I_\Spec$ is correct and does not prune any admissible executions.
This construction is purely semantic and serves only to establish existence.


% \paragraph{Intuition.}
% Intuitively, necessity follows because exposing an observation at a prefix history
% constitutes a semantic commitment, and non-monotonicity means that there exists a
% prefix history and an admissible commitment that causes regret:
% it is contradicted by every causally admissible extension, forcing any correct
% implementation to exclude some admissible executions.

\paragraph{Necessity.}
For the ``only if'' direction, suppose $\Spec$ is non-monotone.
Then there exist histories $H_1 \hext H_2$ and an outcome $o_1 \in \Obs(H_1)$
such that for every $o_2 \in \Obs(H_2)$, $o_1$ and $o_2$ contradict.
Choosing an input history whose external inputs match $H_1$, both $H_1$ and
$H_2$ are admissible extensions.
Any correct implementation must expose some outcome
$o_1 \in \Expose_I(H_1) \subseteq \Obs(H_1)$,
but any such choice is incompatible with correctness
along the admissible extension $H_2$.
Hence any correct implementation must exclude at least one causally admissible
history from $\mathcal{A}(H_{\mathit{in}})$, violating coordination-freedom.
% This necessity argument resonates with the perspective of
% Baccaert et al.~\cite{baccaert2026spectrum}, who study coordination via
% protocol-level restrictions on asynchronous executions.

\paragraph{Tightness.}
The Coordination Criterion is tight: monotonicity is the weakest semantic
condition under which a specification is compatible with all causally
consistent history extensions.
For any strictly weaker condition, there exist specifications that satisfy it
yet admit histories $H_1 \hext H_2$ for which no outcome in $\Obs(H_1)$
is compatible with any outcome in $\Obs(H_2)$.
The formal minimality argument appears in Appendix~\ref{app:minimality}.



% ================================================================
\section{Applications of the Coordination Criterion}
\label{sec:applications}
% ================================================================

We illustrate the reach of the Coordination Criterion through three
representative instantiations, chosen to reflect the perspectives emphasized in
the introduction.
We begin with CAP, a canonical impossibility result, to show how a familiar
coordination tradeoff follows directly from non-monotonicity of a specification.
We then turn to CALM, showing that the same semantic condition applies beyond
object-level consistency, at the level of declarative program semantics—without
committing to a concrete implementation.
Finally, we examine consensus, a classic coordination problem, where coordination can be obscured by suppressing observations, to clarify the boundary of safety-only specifications.
Further applications—including global and atomic snapshots,
commit protocols, transactional isolation
levels, and invariant confluence—are deferred to
Appendix~\ref{sec:additional-applications}.

\paragraph{Unifying pattern.}
In each example below, coordination arises exactly when a specification admits an
observable outcome at a prefix history that cannot be preserved—under the outcome
order—along all causally admissible continuations.
When this happens, correctness forces the exclusion of some admissible histories;
otherwise, coordination-free implementations exist.

\subsection{CAP}

The CAP theorem is a canonical coordination impossibility.
In our framework, it arises directly from the fact that linearizability is a
\emph{non-monotone} specification under asynchronous execution.

\paragraph{$\SpecIt$ sketch.}
Histories are asynchronous executions of a replicated register (Example~\ref{ex:register-specs}).
Outcomes are sequences of completed read and write operations with return values.
For a history $H$, $\Poss(H)$ contains all such sequences realizable by some
causally admissible continuation of $H$.
$\Obs(H)$ restricts these to outcomes admitting a real-time–respecting linearization.
The outcome order $\Ord_{\mathit{lin}}$ is prefix extension on sequences.

\paragraph{Execution pattern.}
Let $H_i$ contain a write of value $1$ at process $p$, followed by a network
partition isolating $p$ from a process $q$; $q$ then issues a read.
Any partition-respecting execution in which the read terminates must return either
the initial value or $1$.
Returning the initial value violates real-time order; returning $1$ asserts
visibility of a write that no such execution can realize.
Thus no terminating read under this partition admits an observable outcome in
$\Obs(H)$.

\paragraph{Diagnosis.}
Linearizability admits an outcome at a prefix history that has no
prefix-compatible extension along some causally admissible continuation.
Preserving correctness therefore requires excluding admissible executions—precisely
coordination.

\paragraph{Corollary: CAP}
No implementation can satisfy linearizable read--write consistency while remaining
both correct on all causally consistent histories and maximally available under
partitions.
Formal definitions appear in Appendix~\ref{app:cap-formal}.

\subsection{CALM}

In contrast to the object-centric CAP setting, CALM operates at the
level of declarative programs.
Among distributed logic programs, the monotone ones are exactly those that admit
coordination-free distributed evaluation~\cite{ameloot2013relational}.

\paragraph{$\SpecIt$ sketch.}
Histories are transducer executions.
Outcomes are output fact sets, with $\Ord_{\mathit{logic}}$ ordered by set inclusion (pointwise over relations).
\(\Poss(H)\) contains fact sets consistent with the program’s declarative semantics
and the inputs observed so far.
\(\Obs(H)\) captures fact sets produced at \(H\).

In monotone logic programs, additional input facts can only add new facts to
observable output sets.
Non-monotone programs—e.g., those with negation or aggregation—may require retracting
previously derived facts as histories extend. This corresponds directly to non-monotonicity of
\(\Obs\) under history extension.
Formal definitions and proofs appear in Appendix~\ref{app:calm-formal}.

% \subsection{Consensus and Related Agreement Tasks}
% \label{sec:consensus}

% Agreement tasks such as consensus form a boundary case for the Coordination
% Criterion.
% Unlike registers, snapshots, or relational transducer programs, they do not
% inherently require observations to be produced incrementally as histories evolve.
% As a result, agreement specifications may appear coordination-free by suppressing
% all observations until a final decision is inevitable.
% This section explains why coordination becomes unavoidable once a specification requires
% observable value commitment, and why suppressing observations does not contradict the Coordination
% Criterion.

% \begin{definition}[Prefix Exposure]
%   \label{def:prefix-exposure}
%   Fix an outcome order $(O,\Ord)$.
%   An \emph{exposure family} is a function
%   $
%     \mathsf{Pre} : O \to \mathcal{P}(O)
%   $
%   such that for every $o \in O$:
%   \begin{enumerate}[nosep]
%     \item \emph{(Prefixes)} every $p \in \mathsf{Pre}(o)$ satisfies $p \Ord o$;
%     \item \emph{(Nontriviality)} $\mathsf{Pre}(o)$ contains at least one
%           \emph{proper} prefix of $o$ whenever $o$ is not $\Ord$-minimal.
%   \end{enumerate}

%   A specification $\Spec=(\Poss,\Ord,\Obs)$ \emph{has prefix exposure w.r.t.}
%   $\mathsf{Pre}$ if for every history $H$ and every outcome $o \in \Obs(H)$,
%   whenever some $p \in \mathsf{Pre}(o)$ is $\Ord$-consistent with $\Obs(H)$
%   (i.e., there exists $o' \in \Obs(H)$ with $p \Ord o'$),
%   we have $p \in \Obs(H)$.
% \end{definition}
% \noindent
% Registers, snapshots, and relational transducer programs satisfy prefix exposure
% under their natural outcome orders.
% Agreement tasks differ precisely in this respect.

% \paragraph{Consensus under prefix exposure.}
% We model consensus using standard decision-map outcomes ordered by pointwise
% extension.
% Under prefix exposure, partial decision maps—recording decisions of some
% processes but not others—must be observable whenever they are semantically
% compatible with the specification.
% This makes intermediate decision commitments visible at prefix
% histories.

% \begin{lemma}[Non-Monotonicity of Consensus]
%   \label{lem:consensus-nonmonotone}
%   Consider the consensus task over a domain with at least two distinct
%   input values.
%   Model histories so that each process first proposes an input value and, upon
%   terminating, performs a decide event recording its decision.

%   Let outcomes be partial functions mapping each process that has decided to its
%   decision value, and let the outcome order $\Ord$ be pointwise extension of these
%   decision maps: $o_1 \Ord o_2$ whenever every decision recorded in $o_1$ also
%   appears with the same value in $o_2$.
%   Let $\Obs(H)$ consist of those decision maps admissible under the consensus
%   specification after history $H$.

%   With this choice of outcomes and outcome order, the consensus specification—
%   requiring validity and agreement—is non-monotone with respect to history
%   extension.
% \end{lemma}

% \begin{proof}[Proof sketch]
%   Consensus typically progresses from initial disagreement to
%   unanimous agreement at completion.
%   Decision maps that record disagreement at a prefix history admit no extension in
%   the outcome order that satisfies agreement.
%   Appendix~\ref{app:consensus-detail} provides a detailed proof.
% \end{proof}

% \begin{lemma}[Silent Consensus is Vacuously Coordination-Free]
%   \label{lem:silent-consensus}
%   There exists a consensus specification that is monotone with respect to history
%   extension and therefore admits a coordination-free implementation.
% \end{lemma}

% \begin{proof}[Proof sketch]
%   Let $\Obs(H)=\{\bot\}$ for all prefix histories $H$, and
%   $\Obs(H)=\{v\}$ only when a decision value $v$ is forced along all causally
%   admissible extensions.
%   Observable outcomes move monotonically from $\bot$ to $v$, so no observation can
%   be invalidated by extension.
% \end{proof}

% \paragraph{Silence versus coordination.}
% If prefix exposure is dropped, a specification may remain silent until a single
% decision value is forced along every causally admissible extension.
% Such a specification is monotone: with no observable commitments, nothing can be
% invalidated by extension.
% This is the familiar FLP-style escape hatch.

% Prefix exposure closes this loophole.
% By requiring semantically compatible outcome prefixes to be observable, it makes
% mid-history commitments explicit.
% It is here—when partial decisions are exposed and later extensions may conflict—
% that coordination becomes unavoidable.

% Viewed through the lens of
% Remark~\ref{rem:faithful-observations}, prefix exposure is a criterion for
% \emph{faithful observation}.
% Silence may preserve correctness, but it obscures where commitments are made and
% where coordination pressure arises.
% For diagnosis rather than permissiveness, observation functions should expose
% intermediate semantic commitments rather than hide them.

\subsection{Consensus and Related Agreement Tasks}
\label{sec:consensus}

Agreement tasks such as consensus form a boundary case for the Coordination
Criterion.
Unlike registers, snapshots, or relational transducer programs, agreement
specifications do not inherently require observations to be produced
incrementally.
As a result, consensus may appear coordination-free if all observations are
suppressed until a final decision is inevitable.
This section explains why such silence does not contradict the Coordination
Criterion, and how coordination becomes unavoidable once a specification requires
observable value commitment.

\begin{definition}[Prefix Exposure]
  \label{def:prefix-exposure}
  Fix an outcome order $(O,\Ord)$.
  A specification \mbox{$\Spec=(\Poss,\Ord,\Obs)$} has \emph{prefix exposure} if the
  following holds:

  For every history $H$ and every outcome $o \in \Obs(H)$, if $o$ is not
  $\Ord$-minimal, then there exists a strict prefix $p \Ord o$ such that
  $p \in \Obs(H)$ whenever $p$ is compatible with the specification at $H$
  (i.e., whenever there exists $o' \in \Obs(H)$ with $p \Ord o'$).
\end{definition}
\noindent
Intuitively, prefix exposure requires that whenever a final outcome is admissible,
any compatible intermediate commitment toward that outcome must already be
observable.
Registers, snapshots, and relational transducer programs satisfy prefix exposure
under their natural outcome orders.
Agreement tasks differ precisely in this respect.

\begin{lemma}[Non-Monotonicity of Consensus]
  \label{lem:consensus-nonmonotone}
  Consider consensus over a domain with at least two values.
  Let outcomes be partial decision maps ordered by pointwise extension, and let
  $\Obs(H)$ contain the decision maps admissible under validity and agreement.
  With prefix exposure, the consensus specification is non-monotone with respect
  to history extension.
\end{lemma}

\begin{proof}[Proof sketch]
  Consensus progresses from partial disagreement to unanimous agreement.
  A decision map that records disagreement at a prefix history admits no extension
  in the outcome order that satisfies agreement.
  See Appendix~\ref{app:consensus-detail} for details.
\end{proof}

\paragraph{Silence versus coordination.}
If prefix exposure is dropped, a specification may remain silent until a single
decision value is forced along all causally admissible extensions.
Such a specification is monotone: with no observable intermediate commitments, nothing can be
invalidated by extension.
This mirrors the classical FLP observation: agreement can preserve safety under
asynchrony by remaining silent indefinitely, even though progress cannot be
guaranteed~\cite{fischer1985impossibility}.

Prefix exposure closes this loophole.
By requiring semantically compatible prefixes to be observable, it exposes
mid-history commitments, precisely where agreement and validity conflict.
In the sense of Remark~\ref{rem:faithful-observations}, prefix exposure is thus another
consideration for faithful diagnosis: silence may preserve correctness, but it hides
where coordination pressure arises.

% ================================================================
\section{Related Work}
% ================================================================

A long line of work in distributed computing characterizes coordination in terms
of epistemic or operational requirements.
Knowledge-based approaches show that certain coordination tasks require common
knowledge or its variants~\cite{halpern1990knowledge,neiger1993simultaneous,neiger1999knowledge},
while task-solvability and hierarchy results characterize which problems can be
solved under given failure and progress assumptions
\cite{fischer1985impossibility,herlihy1991waitfree,herlihy1999topological,saks2000set}.
These frameworks explain when coordination \emph{can be achieved} by strengthening
assumptions about knowledge, synchrony, or oracles.

Our work addresses a complementary question.
Rather than varying environmental or epistemic assumptions to recover solvability,
we fix a minimal asynchronous model and ask whether coordination is
\emph{intrinsic to a specification itself}.
The Coordination Criterion isolates coordination as a semantic obstruction: a
property of observable outcomes under causal history extension, independent of
protocol design, failure detectors, or computational power.

Within this semantic perspective, our work is closest in spirit to the CALM line of
research in declarative networking, which connects coordination-freedom to
monotonicity in distributed computation.
Across this literature—ranging from logic programs and relational
transducers~\cite{hellerstein2010declarative,ameloot2013relational,ameloot2015weaker},
through relation-to-relation semantic mappings~\cite{baccaert2026spectrum}, to
ordered input--output specifications~\cite{li2025coordinationfree}—coordination-freedom
is characterized relative to semantic domains and admissibility assumptions that
are stronger than those of a canonical asynchronous system.

By contrast, our framework makes only the assumptions common to all distributed
systems.
We take Lamport histories as the semantic domain and model specifications
abstractly as sets of admissible histories with observable outcomes ordered by a
refinement relation.
This semantically minimal formulation accommodates arbitrary input and output
structures and any program or machine model, yielding a general diagnostic
criterion for when coordination is unavoidable \emph{without appeal to exogenous
  assumptions}.
As a result, the Coordination Criterion applies directly to the full range of
classical distributed objects, tasks, and consistency conditions studied in this
paper, without translation into a particular language, logic, or
replicated-object formalism (Section~\ref{sec:applications}).
Further discussion of how prior semantic frameworks fit into this model appears in
Appendix~\ref{sec:extended-related-work}.

Brewer’s conjecture and the CAP theorem identify tradeoffs between availability and
strong consistency~\cite{brewer2000towards,gilbert2002cap}.
Traditional formulations fix both a notion of availability and a specific
consistency condition such as linearizability.
Our framework recovers CAP-style impossibility results as direct consequences of
the non-monotonicity of the corresponding specifications, rather than from
availability axioms or failure assumptions.

Conflict-free replicated data types (CRDTs) provide a disciplined implementation
approach to highly available replication by restricting updates to monotone,
inflationary operations~\cite{shapiro2011crdt}.
From our perspective, CRDTs occupy a well-behaved subspace of the monotone
specifications identified by the Coordination Criterion.
Our result characterizes the semantic boundary itself, rather than prescribing a
particular implementation discipline.

Additional connections to knowledge-based models, failure detectors,
transactional isolation, and programming-language support for coordination-free
execution are discussed in Appendix~\ref{sec:extended-related-work}.

% ================================================================
\section{Conclusion}
% ================================================================

We have shown that, in an asynchronous semantic model, a distributed
specification admits a coordination-free correct implementation if and only
if it is monotone with respect to history extension under a chosen outcome
order.
This \emph{Coordination Criterion} unifies classical results across distributed
systems, recovering the semantic content of CAP tradeoffs, CALM-style
monotonicity, snapshots, agreement tasks, and transactional and
invariant-preserving semantics.

In particular, the criterion makes precise how CALM refines CAP.
Non-monotone specifications, such as linearizable registers, intrinsically
require sacrificing consistency or availability under partitions, while monotone
specifications admit coordination-free implementations that are both
partition-tolerant and maximally available.
CALM appears as one instance of this broader semantic boundary, characterizing
those relational programs whose observable outcomes evolve monotonically under history extension.

The Coordination Criterion is also sharp at the semantic level.
Monotonicity is defined relative to an explicit choice of possibility function,
observability function, and outcome order. Any refinement sufficient for
coordination-freedom can be expressed by adjusting this triple rather
than by weakening the criterion itself.
Beyond this boundary, coordination is semantically unavoidable.

Finally, the criterion determines \emph{whether} coordination is required, but
not \emph{how much}.
Some specifications inherently demand multiple, sequential coordination phases,
as in Paxos, where processes must first establish sufficient shared context
before safely committing to decisions.
This points toward a semantic theory of coordination depth and multi-round
coordination.

Our focus here has been on safety-style conditions on observable behavior.
Orthogonal work on coordination-free liveness and free termination
\cite{power2025freetermination} addresses progress guarantees.
Together, these directions suggest a unified view of coordination as a semantic
resource governing which outcomes are treated as observable (i.e., lie in $\Obs(H)$)
and when safe commitment is possible.


% ================================================================
\section*{Acknowledgments}
% ================================================================

Thanks to Peter Alvaro, Natacha Crooks, Paris Koutris, Edward Lee,
Shulu Li and Dan Suciu for helpful feedback.
We also acknowledge the use of AI-based language tools to assist with
drafting and revising the exposition; all technical content and claims
remain the responsibility of the authors.

\appendix

\section{Applications of the Coordination Criterion}
\label{sec:additional-applications}
% % ================================================================
% \section{Applications of the Coordination Criterion}
% \label{sec:applications}
% % ================================================================


% We illustrate the reach of the Coordination Criterion by instantiating it on
% familiar distributed objects, tasks, and consistency models. Rather than
% reproving classical theorems, we show how a single semantic condition on
% specifications pinpoints where coordination is and is not intrinsically
% required. We present CAP and CALM as core instantiations sufficient to evaluate
% the criterion; additional applications—including snapshots, agreement tasks,
% transactional isolation levels, and invariant confluence—are deferred to
% Appendix~\ref{sec:additional-applications}.

\subsection{CAP Revisited}
\label{app:cap-formal}

To discuss CAP formally within our semantic framework, we instantiate a specification
whose observable outcomes correspond to linearizable read--write behavior for a replicated register,
model partitions
via partition patterns that constrain message delivery, and capture availability
using a semantic notion of maximal availability under partitions, defined below.

\begin{definition}[Partition Pattern]
  A \emph{partition pattern} $P$ is a constraint on message delivery that
  specifies which send--receive events are permitted after a given cut of a
  history.
  A history $H$ is said to \emph{respect} $P$ if it contains no message delivery
  events forbidden by $P$.
\end{definition}

\begin{definition}[Maximal Availability Under Partitions]
  \label{def:maximal-availability}
  Fix a specification $\Spec = (\Poss, \Ord, \Obs)$ in the asynchronous model above.
  Let $P$ range over partition patterns and, for a prefix history $H_i$, let
  $\mathsf{Ext}_P(H_i)$ denote the causally consistent extensions $H$ with
  $H_i \hext H$ that respect $P$.
  An implementation $I$ of $\Spec$ is \emph{maximally available under partitions}
  if for every $H_i$, $P$, and client invocation $e \in H_i$, whenever there
  exists some $H \in \mathsf{Ext}_P(H_i)$ such that $\Obs(H) \neq \emptyset$ and
  $e$ completes in $H$, there exists an execution
  $H^* \in \mathsf{Ext}_P(H_i)$ of $I$ such that $\Obs(H^*) \neq \emptyset$ and
  $e$ completes in $H^*$.
\end{definition}

To relate coordination to the CAP tradeoff, we model network partitions as
constraints on which causally consistent history extensions are permitted.
Fix a prefix history $H_i$ and a partition pattern $P$ that forbids delivery on
a subset of channels from some cut onward, and let $\mathsf{Ext}_P(H_i)$ denote
the set of causally consistent extensions $H$ with $H_i \hext H$ that respect $P$.

We say that $(H_i,P)$ is a \emph{witness of unavailability} if, for every history
$H \in \mathsf{Ext}_P(H_i)$, the linearizable specification admits no observable
outcomes, i.e., $\Obs(H)=\emptyset$.
In this case, any implementation that exposes an outcome after $H_i$ under
partition $P$ must produce an observation that is inconsistent with
linearizability.

Reads and writes are operations on a single logical register replicated at
multiple nodes; operations are not replica-indexed.

For the replicated-register running example, let $H_i$ contain a write of value
$1$ at process $p$ followed, after a partition, by a read at process $q$; let
$P$ forbid message delivery from $p$ to $q$.
Any partition-respecting execution in which the read terminates must return
either the initial value or $1$.
Returning the initial value contradicts the outcome order induced by real-time
constraints, while returning $1$ yields an outcome not contained in
$\Poss(H)$ for any history respecting $P$.

This construction shows that pairing a non-monotone specification with maximal
availability yields a witness partition under which any available
implementation must produce observations outside the specification’s observability function.
Instantiating this pattern for linearizable
read--write registers yields the following corollary.

\begin{corollary}[CAP]
  In the asynchronous model above, no implementation of a
  replicated register can satisfy linearizable read--write consistency while
  remaining correct on all causally consistent histories and maximally available
  under partitions (Definition~\ref{def:maximal-availability}).
  Equivalently, any maximally available implementation must, for some prefix
  $H_i$ and partition pattern $P$, violate linearizability
  (i.e., expose outcomes not in $\Obs_{\mathit{lin}}(H)$)
  on every
  partition-respecting extension in $\mathsf{Ext}_P(H_i)$ in which a pending
  operation completes.
\end{corollary}
This follows directly from the non-monotonicity of linearizability and the
Coordination Criterion.

% \begin{proof}[Proof sketch]
%   Linearizability is non-monotone: extending a history with a concurrent write can
%   invalidate a previously admissible read outcome. As shown above, such
%   non-monotonicity yields a witness partition $(H_i,P)$ under which any
%   maximally available implementation must violate the specification, recovering
%   the semantic content of Gilbert and Lynch’s tradeoff~\cite{gilbert2002cap}.
% \end{proof}

\subsection{CALM Revisited}
\label{app:calm-formal}

This appendix makes explicit how the CALM principle arises as a special case of
the Coordination Criterion.
Our goal is not to reprove CALM, but to show that its core semantic insight—
coordination-freedom coincides with monotonicity—follows directly from our
history-based framework under a natural choice of observations and outcome order.

\subsubsection{Relational Transducers and Histories}

We adopt the relational transducer model of
Ameloot et al.~\cite{ameloot2013relational}.
A transducer execution consists of a collection of nodes, each executing the same
logic program, communicating by asynchronous message passing.

A \emph{history} records
(i) the application of rules at nodes,
(ii) message send and receive events, and
(iii) external input facts injected at nodes.
The happens-before relation captures rule dependencies within a node and message
causality across nodes, as in Section~\ref{sec:obs-consistency}.
We impose no fairness or delivery guarantees: messages may be delayed or lost, and
rule application may cease at any node.

\subsubsection{Observations and Outcome Order}

To model eventual consistency, we take outcomes to be \emph{eventual output
  relations}.
Formally, let $O$ be the set of finite or infinite relational instances over the
output schema of the program.
For a history $H$, define $\Poss(H)$ to be the set of output relations that remain
compatible with $H$—that is, relations that are not ruled out by any causally
admissible extension of $H$ under the program semantics.

We equip $O$ with the outcome order $\Ord$ given by set inclusion.
Intuitively, $R_1 \Ord R_2$ means that $R_2$ is a refinement of $R_1$ obtained by
adding facts.
This choice reflects the standard CALM interpretation of eventual outputs: once a
fact appears, it is never retracted.

\subsubsection{Specifications}

A logic program induces a specification $\Spec = (\Poss, \Ord, \Obs)$,
where $\Poss$ and $\Ord$ are as defined above.
For any history $H$, $\Obs(H)$ is the set of output
relations given by the least fixpoint of the program over the input facts
contained in $H$.
That is, $\Obs(H)$ contains the semantically correct relations derivable
given the information available at $H$.
Correctness of an implementation requires that any outcome it exposes at history
$H$ belong to $\Obs(H)$.

Under this interpretation, a specification is \emph{monotone} in our sense if and
only if extending a history cannot invalidate a previously observable output
fact—i.e., every output relation remains extendable by set inclusion along every
causally consistent extension.

\subsubsection{Equivalence with CALM}

We now relate specification monotonicity to program monotonicity.

\begin{lemma}
  A relational transducer program is monotone with respect to set inclusion on input
  facts if and only if the induced specification $\Spec$ is monotone with respect to
  history extension under the outcome order $(O,\subseteq)$.
\end{lemma}

\begin{proof}[Proof sketch]
  If the program is monotone, adding input facts or delaying messages can only add
  derived output facts, never retract them.
  Thus any output relation admissible at a prefix history remains extendable under
  set inclusion at all causal extensions, establishing specification monotonicity.

  Conversely, if the program is non-monotone, there exists a history prefix at which
  some output relation is admissible, but a causally admissible extension (e.g., the
  arrival of an additional input fact or message) invalidates that output.
  This yields a history pair $H_1 \hext H_2$ witnessing non-monotonicity of $\Spec$.
\end{proof}

Applying the Coordination Criterion then yields the CALM equivalence.

\begin{theorem}[CALM, via the Coordination Criterion]
  A relational transducer program admits a coordination-free, eventually consistent
  distributed evaluation if and only if it is monotone with respect to set inclusion
  on input facts.
\end{theorem}

\subsubsection{Relation to CALM and Strict Generalization}

In the CALM setting, program monotonicity and specification monotonicity coincide
because observability is taken to coincide with eventual outputs ordered by inclusion.
Our framework makes clear that this coincidence is a modeling choice, not a
necessity.

More generally, a specification may admit coordination-free implementations even
when internal rules are non-monotone, provided that the observable outcomes
themselves are monotone. It is straightforward to construct such examples by instantiating a transducer with a monotone logic program $P_1$ whose outputs are made observable, and adding rules from a non-monotone logic program $P_2$ whose outputs are not made observable by the transducer, where $P_1$ makes no reference to the relations defined in $P_2$. The \emph{program} $P_1 \cup P_2$ is non-monotone, but the \emph{specification} induced by the transducer is monotone, since only the outputs of $P_1$ are observable.
This separation between internal definitions and observable commitments is
invisible in CALM’s program-centric formulation but central to the Coordination
Criterion.

Thus CALM arises as a clean special case of a more general semantic principle:
coordination is required exactly when observable commitments are non-monotone with
respect to causal extension.

\subsection{Snapshots}

Snapshot objects provide a sharp boundary case for the Coordination Criterion.
Global snapshot and atomic snapshot expose similar interfaces, but differ
fundamentally in how admissible outcomes behave under history extension.

\paragraph{$\SpecIt$ sketch.}
Histories are executions of a shared-memory system with read and write operations.
Outcomes are snapshot results, recording the values of all variables at a single
logical point.

For global snapshot,
$
  \Poss(H) = \Obs(H)
$
is the set of all downward-closed cuts of the happens-before relation realizable
by some causal extension of \(H\).
Here, the outcome order $\Ord_{\mathit{global}}$ is cut extension.

For atomic snapshot, \(\Poss(H)\) is the set of snapshot results realizable under
\emph{some} linearization extending \(H\).
The observability function \(\Obs(H)\) selects snapshot results that the
specification treats as correct at \(H\), each committing to a particular
linearization point.
By contrast, the outcome order $\Ord_{\mathit{atomic}}$ refines linearization-point commitments.

\paragraph{Global snapshot.}
A global snapshot outcome corresponds to a downward-closed cut of
happens-before.
Extending a history can only add events after such a cut, never invalidate it.
Accordingly, every admissible outcome remains compatible with every causally admissible extension.
The specification is monotone and admits coordination-free implementations.

\paragraph{Atomic snapshot.}
In contrast to global snapshot, atomic snapshot commits to a total order rather than a cut.
Atomic snapshot strengthens the specification by requiring each snapshot to
correspond to a single linearization point.
At a prefix history $H$, multiple linearizations of concurrent operations may
remain possible.
Thus $\Poss(H)$ may contain several snapshot results, but observing any one of
them commits to a particular ordering of those operations.

Consider a prefix history $H$ in which a snapshot is concurrent with a write.
At $H$, $\Poss(H)$ includes outcomes corresponding to different linearizations of
the snapshot relative to the write.
Under the linearization-refinement order, these outcomes are incompatible, since
each commits to a distinct total order.
Because causality permits extensions that realize either ordering, committing to
one at $H$ rules out correctness along the other.

Thus atomic snapshot admits observable outcomes at a prefix history that cannot be
preserved under all causally admissible extensions, making coordination intrinsic.

\subsection{Consensus, Commit and Related Agreement Tasks}
\label{app:consensus-detail}
% Clean up... this was cut out from the body and needs framing.
\begin{proof}[Proof of Lemma~\ref{lem:consensus-nonmonotone}]
  Let $v_0$ and $v_1$ be two distinct input values, and let processes $p$ and $q$
  propose $v_0$ and $v_1$, respectively.
  Consider a history $H_1$ in which $p$ has decided $v_0$, $q$ has not yet
  decided, and no other process has decided.
  The outcome $o_1 \in \Obs(H_1)$ maps $p$ to $v_0$ and satisfies both
  validity (every decided value is a proposed value) and agreement (all decided
  values are equal).

  Now extend $H_1$ to a history $H_2$ by adding a decide event for $q$ with
  decision value $v_1$.
  Validity permits this extension, since $v_1$ was proposed by $q$.
  Any observation $o_2$ for $H_2$  must record both
  decisions, so $o_2(p) = v_0$ and $o_2(q) = v_1$.
  No such $o_2$ is admissible under the consensus specification, because
  agreement forbids two different decided values.
  Moreover, any outcome for $H_2$ that extends $o_1$ in the order $\Ord$ must
  preserve $p$'s decision $v_0$, and therefore cannot satisfy agreement when $q$
  decides $v_1$.
  Thus there exist histories $H_1 \hext H_2$ such that an outcome in $\Obs(H_1)$
  has no admissible extension for $H_2$, so the consensus specification
  is non-monotone.
\end{proof}


Commit protocols and quorum thresholds may operate over identical executions;
the distinction lies entirely in what they make observable.

Both can be defined over the same executions: a fixed set of processes cast
votes, and some quorum of votes is eventually obtained.
The distinction lies entirely in the observation function and outcome order.
Atomic commit exposes a binary outcome, $\mathsf{COMMIT}$ or $\mathsf{ABORT}$,
with no common extension; quorum threshold protocols expose only whether a quorum
has been reached, yielding outcomes $\mathsf{UNKNOWN} \Ord \mathsf{DONE}$.

%% FIX THIS DISCUSSION: COMMIT IS MONOTONE WRT OBSERVATION OF A CLOSED WORLD
Under atomic commit, an outcome in $\Obs(H_1)$ for a prefix history can be
inconsistent with every outcome in $\Obs(H_2)$ for some causally consistent
extension $H_1 \hext H_2$.
The specification is therefore non-monotone and cannot admit a
coordination-free implementation.

Under quorum thresholds, every outcome in $\Obs(H_1)$ for a prefix history is
consistent with at least one outcome in $\Obs(H_2)$ for every causally consistent
extension $H_1 \hext H_2$.
The resulting specification is monotone and coordination-free.

\subsection{$k$-set Agreement}
\label{app:agreement-extensions}
%% TODO: reference to Byzantine agreement?
Analogous to the consensus discussion of Section~\ref{sec:consensus}, the natural
observation function for \(k\)-set agreement maps each process that has decided to its decision value and the
corresponding pointwise outcome order. In such a specification, the \(k\)-set agreement specification is
non-monotone for all \(k \ge 1\)~\cite{saks2000set}.
More generally, the same decision-map observation and outcome order witness
non-monotonicity for many other agreement tasks studied in distributed
computability, including standard multi-valued and Byzantine agreement
variants.

\subsection{Strong Renaming}
\label{app:strong-renaming}
\begin{corollary}[Strong Renaming]
  \label{cor:renaming}
  The strong renaming task~\cite{herlihy1999topological} is non-monotone with
  respect to history extension and therefore intrinsically requires coordination:
  the set of admissible name assignments can shrink when additional participants
  or concurrency are introduced.
\end{corollary}

\begin{proof}[Proof sketch]
  In the strong renaming task, each participating process must acquire a unique
  name from a namespace whose size depends on the number of participating
  processes, so correctness depends on the maximal concurrency of the
  execution.
  Because the allowed name space depends on the set of participants, extending a
  history by adding new participants or overlapping their executions can shrink
  the set of admissible name assignments.
  Classical renaming results (e.g., in the wait-free hierarchy and topological
  computability literature~\cite{herlihy1991waitfree,herlihy1999topological})
  indeed exhibit executions $H_1 \hext H_2$ in which an assignment of names
  that satisfies strong renaming on $H_1$ cannot be extended to any assignment
  that satisfies strong renaming on $H_2$ while keeping the original names fixed
  for the processes that participated in $H_1$.
  Such non-monotonicity implies, by the Coordination Criterion, that strong
  renaming intrinsically requires coordination, independently of the particular
  wait-freedom or solvability assumptions made in classical hierarchy results.
\end{proof}
Strong renaming thus isolates a distinct source of non-monotonicity: admissibility
of observations depends on the eventual set of participating processes.
Unlike snapshots or registers, no interpretation of operations is involved; the
specification itself is sensitive to unresolved membership.
This membership sensitivity reappears in consensus, where it interacts
with value commitment.

\subsection{Transactional Isolation Levels}
\label{app:isolation}

Classical work on transactions distinguishes a spectrum of isolation levels,
often characterized by which anomaly patterns they forbid on transactional
executions~\cite{berenson1995critique}.
Subsequent work, most notably that of Bailis et al., identified a boundary
between isolation levels that admit highly available implementations under
asynchrony and partitions and those that intrinsically require
coordination~\cite{bailis2013hat}.
We recover this boundary semantically via monotonicity.

\paragraph{Histories and observations.}
We model transactional executions as histories whose events include transaction
invocations, read and write operations on shared objects, and commit or abort
decisions.
We restrict attention to committed transactions, treating aborts as producing
no observable effects.

An \emph{outcome} is a finite set of atomic facts of the form
\[
  \mathsf{commit}(T)
  \quad\text{and}\quad
  \mathsf{read}(T,x,v),
\]
where $\mathsf{commit}(T)$ records that transaction $T$ has committed, and
$\mathsf{read}(T,x,v)$ records that transaction $T$, upon committing, returned
value $v$ for a read of location $x$.
Each read fact is associated with a specific transaction and location.


Define $\Poss(H)$ to be the singleton set containing the outcome consisting of all
such facts induced by the committed transactions in $H$.
This reflects that transactional histories deterministically determine which
commit and read facts have already occurred; uncertainty arises only from which
additional transactions may commit in future extensions.

\paragraph{Outcome order.}
We order outcomes by set inclusion:
\[
  o_1 \Ord o_2 \quad\text{iff}\quad o_1 \subseteq o_2.
\]
Under this order, one outcome refines another precisely by recording additional
observable facts, corresponding to additional committed transactions or
additional read results.

\paragraph{Isolation levels as specifications.}
An isolation level $L$ is modeled as a specification
\[
  \Spec_L = (\Poss, \Ord, \Obs_L),
\]
where $\Obs_L(H)$ consists of those outcomes in $\Poss(H)$ that satisfy
the constraints imposed by $L$.
That is, $\Obs_L(H) \subseteq \Poss(H)$, and an outcome is treated as observable at
$H$ exactly when it lies in $\Obs_L(H)$.
These constraints may forbid particular combinations of read and commit facts,
corresponding to classical anomalies such as dirty reads, lost updates, or
write skew.

Crucially, isolation levels differ in whether the anomalies they forbid are
\emph{prefix-closed} with respect to history extension.
An anomaly is prefix-closed if, once it appears in an outcome, no history extension
can eliminate it without producing an outcome that fails to extend the original
one under the outcome order.

\paragraph{Monotone isolation levels.}
Isolation levels such as read uncommitted, read committed, and session guarantees
in the sense of Terry et al.~\cite{terry1994session} forbid only prefix-closed
anomalies.
For these levels, if $o \in \Obs_L(H)$, then for any extension $H' \hext H$ there
exists $o' \in \Obs_L(H')$ with $o \subseteq o'$:
extending the history may add further committed transactions and read facts, but
cannot invalidate existing ones.
Accordingly, the induced specification $\Spec_L$ is monotone with respect to
history extension.
By the Coordination Criterion, these isolation levels admit coordination-free
implementations.

\paragraph{Non-monotone isolation levels.}
By contrast, isolation levels that require a global serialization or snapshot
order---including serializable isolation and snapshot isolation---are
non-monotone.
For such levels, there exist histories $H_1 \hext H_2$ and an outcome
$o_1 \in \Obs_L(H_1)$ such that no outcome in $\Obs_L(H_2)$ extends $o_1$ under
$\Ord$.
Intuitively, an outcome in $\Obs_L(H_1)$ for a partial execution
may become incompatible once the history is extended with additional committed
transactions that constrain the required global order.
Any implementation that preserves correctness under these specifications must
therefore exclude some causally consistent executions and introduce
coordination.

For exposition, we provide a concrete example for snapshot isolation;
analogous examples exist for serializability and other non-monotone levels.
\begin{example}[Non-Monotonicity under Snapshot Isolation]
  \label{ex:si-nonmonotone}
  Consider two transactions $T_1$ and $T_2$ operating on variables $x$ and $y$,
  both initially $0$.
  Transaction $T_1$ reads $x$ and writes $y := 1$; transaction $T_2$ reads $y$ and
  writes $x := 1$.

  Let $H_1$ be a history in which $T_1$ has executed and committed, while $T_2$
  has not yet decided.
  The observation
  \[
    o_1 = \{\mathsf{commit}(T_1), \mathsf{read}(T_1,x,0)\}
  \]
  is admissible under snapshot isolation: $T_1$ can read from an initial snapshot
  and commit.

  Now extend $H_1$ to a history $H_2$ by adding a committing execution of $T_2$ in
  which $T_2$ reads $y = 0$.
  Any observation $o_2$ for $H_2$ must include both read results:
  \[
    o_2 = o_1 \cup \{\mathsf{commit}(T_2), \mathsf{read}(T_2,y,0)\}.
  \]
  However, no such $o_2$ is admissible under snapshot isolation.
  The read of $x=0$ by $T_1$ requires $T_1$'s snapshot to precede $T_2$'s write to
  $x$, while the read of $y=0$ by $T_2$ requires $T_2$'s snapshot to precede
  $T_1$'s write to $y$, yielding a cyclic snapshot order.

  Thus there exist histories $H_1 \hext H_2$ and an observation $o_1 \in \Obs(H_1)$
  such that no observation in $\Obs(H_2)$ extends $o_1$.
  The snapshot isolation specification is therefore non-monotone with respect to
  history extension.
\end{example}

\paragraph{Discussion.}
This example isolates the semantic distinction underlying prior results on highly
available transactions.
Coordination-freedom is determined neither by the use of transactions nor by
progress guarantees, but by whether an isolation level’s correctness constraints
are monotone under history extension.

Isolation levels such as read committed or session guarantees impose only
prefix-closed constraints: for any $o \in \Obs_L(H_1)$, there is for each causally
consistent extension $H_1 \hext H_2$ some $o' \in \Obs_L(H_2)$ consistent with $o$.
By contrast, stronger levels—including snapshot isolation and serializability—
admit histories for which some $o \in \Obs_L(H_1)$ is inconsistent with every
$o' \in \Obs_L(H_2)$ for some causally consistent extension $H_1 \hext H_2$.
Preserving consistency in such cases requires coordination to resolve these
incompatible observations to a single outcome.

Viewed imperatively, this corresponds to the familiar distinction that highly
available isolation levels permit transactions to commit independently, whereas
stronger isolation levels require commitments that are mutually constraining.

\subsection{Invariant Confluence}

Coordination-free execution has also been studied for application-level
invariants.
Bailis et al.\ introduce \emph{invariant confluence} ($I$-confluence) and show
that some invariants can be preserved without coordination in replicated
databases, while others fundamentally require it~\cite{bailis2014coordination}.

We model such systems as histories whose events include transaction invocations,
replica-local updates, and merge operations.

An \emph{outcome} represents uncertainty about the database state after a history.
Formally, the outcome domain $O$ consists of sets of database states, where an
outcome $o \in O$ represents the set of states that may be reachable.
We order outcomes by set inclusion:
\[
  o_1 \Ord o_2 \quad\text{iff}\quad o_1 \subseteq o_2,
\]
so that refinement corresponds to ruling out states.

The possibility function $\Poss(H)$ consists of all outcomes representing sets of
database states that remain reachable under some causally admissible extension of
history $H$.

Given an application invariant $I$, the specification
\[
  \Spec_I = (\Poss, \Ord, \Obs_I)
\]
defines $\Obs_I(H)$ to be those outcomes $o \in \Poss(H)$ in which every state
satisfies the invariant:
\[
  \Obs_I(H) = \{\, o \in \Poss(H) \mid \forall s \in o.\; I(s) \,\}.
\]

If $I$ is $I$-confluent, then extending a history with additional locally valid
transactions and merges cannot introduce a reachable state that violates $I$.
Equivalently, for all histories $H_1 \hext H_2$ and all $o \in \Obs_I(H_1)$, there
exists $o' \in \Obs_I(H_2)$ such that $o \Ord o'$.
Thus the specification $\Spec_I$ is monotone with respect to history extension and,
by the Coordination Criterion, admits coordination-free implementations.

If $I$ is not $I$-confluent, there exist histories $H_1 \hext H_2$ and an outcome
$o \in \Obs_I(H_1)$ such that no outcome in $\Obs_I(H_2)$ extends $o$ under $\Ord$.
In this case, $\Spec_I$ is non-monotone and enforcing $I$ necessarily requires
coordination.

\paragraph{Discussion.}
At first glance, this correspondence may appear tautological: $I$-confluence is
defined so as to permit coordination-free execution.
The contribution of the Coordination Criterion is to locate this property at the
level of \emph{specifications} rather than merge semantics or replica behavior.
Invariant confluence emerges here as a special case of a general semantic
boundary: application invariants admit coordination-free enforcement precisely
when their observable outcomes are monotone under history extension.
This reframes $I$-confluence not as a separate theory of coordination, but as an
instance of the same monotonicity principle that governs registers, snapshots,
agreement, and transactional isolation.

%% -------------------------------------------------------------
\section{Proof of the Coordination Criterion}
\label{app:coordination-criterion-proof}
%% -------------------------------------------------------------

For completeness we restate and fully prove Theorem~\ref{thm:coordination-criterion}.

\begin{theorem}[Coordination Criterion, restated]
  A distributed specification admits a coordination-free
  implementation if and only if it is monotone with respect to history
  extension under the chosen outcome order $\Ord$.

  This equivalence is proved under the asynchronous message-passing model of
  Section~\ref{sec:obs-consistency}, in which histories may be finite or infinite,
  messages may be delayed or lost, and crashes are modeled as processes that take
  no further steps.
  We assume that $\Ord$ is a partial order on observable outcomes and that each
  specification $\Spec = (\Poss, \Ord, \Obs)$ has a total admissibility function
  $\Obs : \Hist \rightarrow \mathcal{P}(O)$ (it is defined on every history in $\Hist$).
  No progress or fairness assumptions (such as termination or wait-freedom) are
  required for the theorem itself.
\end{theorem}

\begin{proof}
  We have to prove both directions of the equivalence.
  Throughout the proof, when we speak of an outcome exposed by an implementation
  at a history $H$, we mean an outcome that the implementation may expose at $H$
  and that is required by correctness to lie in $\Obs(H)$.

  \medskip
  \noindent\textsc{\emph{Sufficiency.}}
  Fix a specification $\Spec = (\Poss, \Ord, \Obs)$ that is monotone with respect to $\hext$ and the
  chosen outcome order $\Ord$.
  To prove sufficiency, we must exhibit an implementation $I_\Spec$ that is
  coordination-free in the sense of the preceding definition: for every
  admissible input history $H_{\mathit{in}}$, its realizable histories satisfy
  that, for all $H \in \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$, the implementation
  chooses some outcome $o(H) \in \Obs(H)$ and
  $\mathcal{R}_{I_\Spec}(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$.

  \emph{Construction of $I_\Spec$.}
  We give an idealized operational model in which the implementation's state
  records the current history and the implementation does not introduce any
  additional restrictions on admissible executions beyond causal consistency.
  This construction is purely semantic and existential: it serves only to witness
  coordination-freedom and is not intended to be realizable by any finite-state or
  practical protocol.
  For each admissible input history $H_{\mathit{in}}$, consider a labeled
  transition system whose configurations are histories $H \in \Hist$ with
  $H_{\mathit{in}} \hext H$.
  The initial configuration is $H_{\mathit{in}}$.
  There is a transition $H \rightarrow_I H'$ whenever all of the following hold:
  (i) $H \hext H'$; (ii) $H'$ extends $H$ by a single event (i.e., if
  $H = (E,\rightarrow)$ and $H' = (E',\rightarrow')$, then
  $E' = E \cup \{e\}$ for some event $e$); and (iii) $H'$ respects the
  asynchronous message-passing constraints of Section~\ref{sec:obs-consistency}
  (in particular, it extends the local program order and send/receive edges and
  may delay or drop messages).
  Intuitively, $I_\Spec$ maintains the exact history generated so far and
  allows any single-event causally admissible extension.
  For each history $H$, the implementation nondeterministically chooses
  some outcome $o_H \in \Obs(H)$ to expose.
  Because $\Obs(H) \subseteq \Poss(H)$ by definition of a specification,
  every exposed outcome is causally possible at $H$.
  Monotonicity of $\Spec$ ensures that every such choice remains $\Ord$-compatible
  with at least one outcome in $\Obs(H')$ for every extension $H \hext H'$.

  \emph{Correctness.}
  By construction, for every admissible input history $H_{\mathit{in}}$ and every
  realizable history $H \in \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$, the
  implementation reports some outcome $o_H \in \Obs(H)$.
  Thus clause~(i) of coordination-freedom holds.

  \emph{No additional pruning.}
  Fix an admissible input history $H_{\mathit{in}}$.
  By construction, every run of $I_\Spec$ from $H_{\mathit{in}}$ produces a
  chain of histories
  \[
    H_{\mathit{in}} = H_0 \hext H_1 \hext H_2 \hext \cdots
  \]
  in which each step adds a single event consistent with the asynchronous
  semantics.
  The limit of this chain (for a finite or infinite run) is a history
  $H \in \Hist$ with $H_{\mathit{in}} \hext H$ that respects causality, so
  $H \in \mathcal{A}(H_{\mathit{in}})$.
  Thus every realizable history is asynchronously admissible and
  $\mathcal{R}_{I_\Spec}(H_{\mathit{in}}) \subseteq \mathcal{A}(H_{\mathit{in}})$.

  For the converse inclusion, take any history $H \in \mathcal{A}(H_{\mathit{in}})$.
  Because $H$'s happens-before relation is a partial order and its event set is
  finite or countably infinite, there exists a linear extension (topological
  ordering) $e_1,e_2,\ldots$ of the events of $H$ restricted to those not already
  in $H_{\mathit{in}}$ such that every predecessor of $e_k$ in $H$ appears among
  $\{e_1,\ldots,e_{k-1}\}$.
  We construct a run of $I_\Spec$ that realizes $H$ by induction on $k$.
  Base: the initial configuration is $H_{\mathit{in}}$.
  Inductive step: suppose the current configuration is some history $H^{(k-1)}$
  with $H_{\mathit{in}} \hext H^{(k-1)} \hext H$ containing exactly the events
  $e_1,\ldots,e_{k-1}$ in addition to those of $H_{\mathit{in}}$.
  By the choice of linear extension, all predecessors of $e_k$ in $H$ are already
  in $H^{(k-1)}$, so adding $e_k$ yields a history $H^{(k)}$ with
  $H^{(k-1)} \hext H^{(k)} \hext H$ that respects the asynchronous constraints.
  By the transition rule, there is a step $H^{(k-1)} \rightarrow_I H^{(k)}$.
  Thus by induction we obtain a (finite or infinite) run whose limit history is
  exactly $H$.
  Hence $H \in \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$, so
  $\mathcal{A}(H_{\mathit{in}}) \subseteq \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$.

  Combining both inclusions, we obtain
  $\mathcal{R}_{I_\Spec}(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$ for
  every admissible input history $H_{\mathit{in}}$.
  Together with correctness, this shows that $I_\Spec$ is coordination-free for
  $\Spec$.

  \begin{remark}[On the idealized sufficiency construction]
    The implementation $I_\Spec$ constructed in the sufficiency proof is deliberately
    idealized and semantic.
    It should not be read as a protocol sketch or as asserting implementability in any
    realistic computational model.
    Rather, it serves as an \emph{existence witness}: it demonstrates that when a
    specification is monotone, there is no \emph{semantic obstruction} to realizing all
    causally admissible histories while remaining observationally correct.
    The construction isolates coordination as a purely semantic phenomenon—arising
    only from the need to exclude causally consistent executions—and separates this
    concern from issues of computability, state representation, or protocol design,
    which are orthogonal to the Coordination Criterion.
  \end{remark}

  \medskip
  \noindent\textsc{\emph{Necessity.}}
  Conversely, suppose $\Spec$ is non-monotone.
  Then there exist histories $H_1 \hext H_2$ and an outcome
  $o_1 \in \Obs(H_1)$ such that for every $o_2 \in \Obs(H_2)$,
  $o_1$ and $o_2$ contradict under $\Ord$.

  Because $H_1 \hext H_2$, we may choose an admissible input history
  $H_{\mathit{in}}$ that contains exactly the external input events of $H_1$.
  Both $H_1$ and $H_2$ are causally consistent extensions of $H_{\mathit{in}}$,
  so $H_1,H_2 \in \mathcal{A}(H_{\mathit{in}})$.

  Assume for contradiction that there exists an implementation $I$ that is both
  correct for $\Spec$ and coordination-free.
  By coordination-freedom,
  $\mathcal{R}_I(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$, so in particular
  $H_1,H_2 \in \mathcal{R}_I(H_{\mathit{in}})$.

  Fix a run of $I$ from $H_{\mathit{in}}$ whose resulting history is $H_2$, and
  consider the prefix of this run obtained by stopping immediately after the last
  event of $H_1$.
  This prefix is itself an admissible run of $I$ (our asynchronous model imposes
  no fairness obligations), and its history is exactly $H_1$.
  Thus there exist two runs of $I$ from the same input history $H_{\mathit{in}}$
  that coincide up to history $H_1$ but whose admissible
  extensions realize $H_1$ and $H_2$ respectively.

  Because $\Obs(H_1)$ and $\Obs(H_2)$ contradict, there is no single observation
  $o$ that is compatible with both under $\Ord$.
  Because correctness requires $\Expose_I(H_1) \subseteq \Obs(H_1)$, and
  $\Obs(H_1)$ contains at least one admissible outcome, the implementation must
  commit to some outcome in $\Obs(H_1)$ along any run realizing $H_1$.
  Any such choice will be incompatible with every outcome in $\Obs(H_2)$ along the
  admissible extension to $H_2$.

  To remain correct on all admissible runs from $H_{\mathit{in}}$, $I$ must therefore
  exclude at least one of the causally consistent extensions $H_1$ or $H_2$.
  Equivalently,
  $\mathcal{R}_I(H_{\mathit{in}}) \subsetneq \mathcal{A}(H_{\mathit{in}})$,
  contradicting coordination-freedom.
  Hence no implementation can be both correct for a non-monotone specification and
  coordination-free.

  \begin{remark}[On the necessity argument]
    The necessity direction does not rely on any assumptions about how or when an
    implementation exposes observations, nor on liveness, fairness, or output
    timing.
    It uses only the fact that a correct implementation must associate \emph{some}
    outcome in $\Obs(H)$ with every history it realizes.
    When a specification is non-monotone, this requirement alone forces a conflict:
    any outcome in $\Obs(H_1)$ at a prefix history may be rendered incompatible with
    all outcomes in $\Obs(H_2)$ required by some causally admissible extension.
    Thus the impossibility arises from semantic incompatibility under history
    extension, not from operational constraints or protocol-level limitations.
  \end{remark}

  \paragraph{Relation to FLP-style impossibility results.}
  The necessity direction of the Coordination Criterion has a close structural
  affinity with classical FLP-style impossibility arguments~\cite{fischer1985impossibility}.
  In both cases, the core obstruction is not a lack of progress or fairness, but
  the existence of two causally admissible extensions of the same prefix history
  that force incompatible semantic commitments.
  FLP exhibits this phenomenon operationally, by constructing executions in which
  any attempt to decide eventually leads to a contradiction under asynchrony.
  Here, we isolate the same obstruction semantically: non-monotonicity witnesses
  a prefix at which every outcome in $\Obs(H_1)$ would be invalidated by some
  causally consistent extension.
  The Coordination Criterion can thus be read as a semantic generalization of the
  FLP insight, characterizing exactly when such contradictions are unavoidable,
  independently of any particular task or protocol.
  Conversely, classical wait-free tasks like snapshots and CRDT-style objects
  fit the monotone side of the criterion: their specifications ensure that every
  locally observable outcome remains compatible with all causally consistent
  extensions, explaining why they admit coordination-free implementations despite
  unbounded delay.
\end{proof}

% ================================================================
\section{Minimality of the Coordination Criterion}
\label{app:minimality}
% ================================================================

This appendix clarifies the sense in which the Coordination Criterion is
\emph{minimal}.
The result does not claim that monotonicity is the only natural semantic
condition one might impose.
Rather, it shows that monotonicity is unavoidable at the semantic level:
any specification that admits a coordination-free implementation induces
a monotone structure under a suitable outcome order.
In this sense, monotonicity is not a modeling choice but an intrinsic
property of coordination-free behavior.

\begin{proposition}[Semantic Minimality]
  Let $\mathcal{C}$ be any class of distributed specifications such that every
  $\Spec \in \mathcal{C}$ admits a coordination-free consistent implementation
  in the asynchronous model.
  Then for each $\Spec \in \mathcal{C}$ there exists an outcome order $\Ord$
  such that $\Spec$ is monotone with respect to history extension under $\Ord$.
\end{proposition}

\begin{proof}[Proof sketch]
  Fix a specification $\Spec = (\Poss,\Ord,\Obs)$ that admits a coordination-free
  implementation $I$.
  By definition of coordination-freedom, for every admissible input history
  $H_{\mathit{in}}$, the implementation realizes exactly the set
  $\mathcal{A}(H_{\mathit{in}})$ of causally admissible extensions.

  For each history $H$, let $\Obs_I(H)$ denote the set of outcomes that $I$ may
  expose at $H$ across its admissible executions.
  Observational correctness ensures $\Obs_I(H) \subseteq \Obs(H)$ for all $H$.

  Because $I$ does not exclude any causally admissible extension, extending a
  history cannot invalidate all future realizations of an exposed outcome:
  for any $H_1 \hext H_2$ and any $o \in \Obs_I(H_1)$, there exists
  $o' \in \Obs_I(H_2)$ that arises along some admissible extension.

  Ordering outcomes by this extension relation yields an outcome order under which
  $\Spec$ is monotone with respect to history extension.
  This derived outcome order reflects semantic compatibility induced by the
  implementation itself: two outcomes are ordered precisely when the
  implementation can realize them along a common causal extension.
\end{proof}

\paragraph{Discussion.}
The construction above is intentionally coarse and serves only to establish
semantic minimality.
It shows that any semantic condition sufficient to characterize
coordination-freedom can be re-expressed as monotonicity of a specification
under an appropriate outcome order.
Thus refinements of monotonicity arise from changing the semantic interface,
not from weakening the Coordination Criterion itself.

\section{Extended Related Work}
\label{sec:extended-related-work}

\paragraph{Distributed Computability.}
Classical results on agreement and wait-free computation characterize task
solvability and object hierarchies
\cite{fischer1985impossibility,herlihy1991waitfree,herlihy1999topological,saks2000set}.
Our Coordination Criterion is complementary to these theories: it isolates when
coordination is semantically required at the level of observable behaviors,
while topological and hierarchy results determine which tasks are solvable, and
with which primitives, under progress assumptions such as wait-freedom.

\paragraph{Knowledge and Failure Detectors.}
Knowledge-based approaches characterize coordination in terms of what processes
know about the global state of the system: for example, common knowledge has
been shown to be necessary for certain forms of simultaneous coordination
\cite{halpern1990knowledge,neiger1993simultaneous}.
Failure-detector frameworks such as that of Chandra and Toueg
\cite{chandra1996unreliable} parameterize when tasks like consensus are
solvable by strengthening the environment through oracles that eventually
convey enough information about crashes.
These perspectives are complementary to ours: they characterize when coordination
becomes possible by strengthening agents’ knowledge or the execution environment,
whereas we fix a minimalist asynchronous model and identify when coordination is
\emph{semantically unavoidable} because the specification itself is non-monotone.


\paragraph{CAP}
Brewer’s conjecture and the CAP theorem establish tradeoffs between availability
and strong consistency \cite{brewer2000towards,gilbert2002cap}.
Classical CAP formulations fix both a particular notion of availability (e.g.,
non-blocking responses during partitions) and a specific class of consistency
conditions such as linearizability.
Section~\ref{sec:applications} instantiates our framework with linearizable
read--write registers to recover this tradeoff as a direct consequence of the
non-monotonicity of the corresponding specification, rather than from availability
axioms or failure assumptions.

\paragraph{CALM and Generalizations.}
The Coordination Criterion is closest in spirit to the CALM line of work, which
connects coordination-freedom to monotonicity in declarative distributed
computation.
This literature—including relational transducers and logic-based models—studies
coordination relative to semantic domains and execution assumptions that are
stronger than those of a canonical asynchronous system
\cite{hellerstein2010declarative,ameloot2013relational,ameloot2015weaker}.

The most recent work in this line, by Baccaert and Ketsman~\cite{baccaert2026spectrum},
moves beyond language-specific analyses by modeling distributed computation as
semantic mappings between relations and parameterizing coordination-freedom by a
family of \emph{system constraints}.
These constraints restrict which executions are admissible, yielding a spectrum
of monotonicity conditions under increasingly strong assumptions.
While this advances the CALM program toward a more semantic treatment of
admissibility, it remains framed within a relation-to-relation computational model
with fixed input and output structures.

Li and Lee~\cite{li2025coordinationfree} pursue a complementary abstraction,
formulating coordination-freedom at the level of ordered input--output
specifications.
Their formulation abstracts away from particular programming models but still
assumes a fixed notion of admissible executions and partitioning.

By contrast, our work makes no assumptions beyond standard causality.
We take Lamport histories as the semantic domain and define specifications
abstractly via admissible histories and observable outcomes ordered by refinement.
This semantically minimal formulation accommodates arbitrary input and output
structures and any program or machine model, yielding a general diagnostic
criterion for when coordination is \emph{intrinsic to the specification itself}.
Because it relies only on causality and semantic refinement—rather than on program
semantics, constraint regimes, or execution assumptions—the Coordination Criterion
applies directly to the full range of classical distributed objects, tasks, and
consistency conditions studied in this paper, without translation into a
particular language, logic, or replicated-object formalism
(cf.~Section~\ref{sec:applications} and
Appendix~\ref{sec:additional-applications}).

We also note a connection to Gallifrey~\cite{milano2019tour}, which makes
monotonicity explicit in the type system by requiring programmers to specify the
order with respect to which values evolve.
This design choice influenced our decision to reify observability and outcome
order as first-class components of a specification.


\paragraph{CRDTs.}
Work on conflict-free replicated data types (CRDTs) provides a programming
discipline for highly available replicated objects under eventual
consistency~\cite{shapiro2011crdt}.
CRDTs propose a constrained programming model: state
spaces are join-semilattices and updates are restricted to inflationary,
commutative operations, so that replicas converge without explicit
coordination.
This yields a robust recipe for building highly available replicated data
types.
Our theorem is complementary: it is phrased at the level of semantic
specifications rather than implementation disciplines.
From this perspective, CRDTs occupy a well-behaved sub-region of the monotone
specification space identified by the Coordination Criterion: they show how to
implement certain coordination-free specifications, but do not characterize
the full semantic boundary between coordination-free and coordination-requiring
behavior.

\paragraph{Transactional and Weak Consistency Semantics.}
History- and anomaly-based characterizations of transactional isolation levels
and weak consistency models
\cite{adya2000generalized,berenson1995critique,crooks2017seeing}
analyze which behaviors client programs can observe under different guarantees.
Given any such model as a specification in our sense, monotonicity of its
observable outcomes predicts whether it admits coordination-free
implementations; Appendix~\ref{sec:additional-applications} applies this lens
to the HAT versus non-HAT isolation levels and to invariant-preserving
replicated transactions.

\paragraph{Programming Languages for Coordination-Free Distributed Systems.}

A parallel line of work in programming languages has sought to make
coordination requirements explicit or avoidable through language design.
Rather than treating coordination as an emergent property of low-level
protocols, these systems structure programs so that safe distributed
execution follows from semantic restrictions on state, effects, or time.

Gallifrey~\cite{milano2019tour} is a functional language for distributed
programming that makes temporal structure explicit in the type system.
Programs are required to specify the order with respect to which values evolve,
making monotonicity a typed semantic obligation rather than an implicit property
of an implementation.
From our perspective, this corresponds directly to making the outcome order
explicit: only values that are stable under all causal extensions relative to the
chosen order may be exposed.
Gallifrey thus enforces observational stability by construction and influenced our
decision to reify observability and outcome order as first-class components of a
specification.

Flo~\cite{laddad2024flo} takes a complementary approach through reactive
dataflow.
Programs define continuously evolving signals whose values may be refined as new
inputs and events arrive.
The language enforces monotonicity and inflationarity constraints on observable
state, ensuring that outputs may grow or refine but are never semantically
retracted.
Although Flo is presented operationally as a dataflow system, its guarantees
align closely with monotone specifications in our sense: once an outcome becomes
observable, it remains compatible with all future observations.

Earlier systems explored similar ideas in more operational or
domain-specific forms.
Dedalus~\cite{alvaro2010dedalus} introduced a temporal logic programming model
that makes asynchrony explicit by separating deductive, inductive, and
asynchronous rules.
This separation exposed the semantic role of time and causality in distributed
programs and directly motivated the CALM conjecture.
Bloom~\cite{alvaro2011bloom} built on Dedalus to provide a practical programming
model in which monotone programs admit coordination-free execution, while
non-monotone constructs require explicit coordination mechanisms.

Lasp~\cite{meiklejohn2015lasp} represents a different point in the design space,
centered on replicated data types rather than logic or dataflow.
By restricting shared state to join-semilattices and updates to inflationary
operations, Lasp ensures that replicas converge without coordination.
In semantic terms, Lasp enforces monotonicity by construction at the level of
observable outcomes, guaranteeing that all exposed results remain compatible
under causal extension.

Across these systems, the common insight is not a particular programming model
but a semantic constraint: coordination becomes necessary exactly when a program
attempts to expose outcomes that are not stable under asynchronous evolution.
Each language identifies fragments in which observable behavior evolves
monotonically.
The Coordination Criterion generalizes this insight, characterizing the semantic
boundary itself—independently of language, type system, or execution strategy.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
