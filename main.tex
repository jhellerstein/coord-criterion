\documentclass[acmsmall,nonacm,anonymous]{acmart}

% Ensure the non-ACM draft compiles cleanly under acmart without conference metadata.
\settopmatter{printacmref=false,printccs=false,printfolios=true}
\renewcommand\footnotetextcopyrightpermission[1]{}
\acmConference[]{}{}{}
\acmBooktitle{}
\acmYear{}
\copyrightyear{}

% ---------- Space saving, etc ----------
\usepackage{microtype}
\usepackage{enumitem}
\usepackage{multicol}
\usepackage{etoolbox}

\makeatletter
\pretocmd{\@begintheorem}{\setlength{\topsep}{2pt}}{}{}
\pretocmd{\@endtheorem}{\setlength{\topsep}{2pt}}{}{}
\makeatother

% acmart forbids this
% \makeatletter
% \renewcommand\parhead{\@startsection{paragraph}{4}{\z@}%
%   {-0.5ex \@plus -0.2ex \@minus -0.2ex}%
%   {-0.8em}%
%   {\normalfont\normalsize\itshape}}
% \makeatother

\usepackage{xparse}

\NewDocumentCommand{\parhead}{m}{%
  % \par\addvspace{-0.5ex}%
  \noindent{\normalfont\normalsize\itshape #1}\hspace{0.6em}%
}

% ---------- Theorem environments ----------
% \newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
% \theoremstyle{remark}
% \newtheorem{remark}{Remark}
% % \newtheorem{example}{Example}

% --- tighter theorem spacing (definitions/remarks/examples) ---
\makeatletter
\newtheoremstyle{tight}
  {0.25\baselineskip} % Space above
  {0.25\baselineskip} % Space below
  {\normalfont}         % Body font (adjust per env via \theoremstyle below)
  {}                 % Indent amount
  {\itshape}        % Head font
  {.}                % Punctuation after head
  {0.5em}            % Space after head
  {}                 % Head spec
\makeatother

% Use upright body for def/remark if you prefer:
\theoremstyle{tight}
\newtheorem{definition}{Definition}
\newtheorem{remark}{Remark}

% \usepackage{mdframed}
% \newmdtheoremenv{example}{Example}

% \newtheorem{exampleinner}{Example}
% \newcommand{\exampleend}{\hfill$\diamond$}
% \newenvironment{example}
%   {\begin{exampleinner}}
%   {\exampleend\end{exampleinner}}

\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{amsthm}

% Define a very light gray
\definecolor{examplegray}{gray}{0.85}

\newtheorem{exampleinner}{Example}

\newmdenv[
  linecolor=examplegray,
  linewidth=0.6pt,
  roundcorner=3pt,
  innertopmargin=0.1\baselineskip,
  innerbottommargin=0.4\baselineskip,
  innerleftmargin=0.5em,
  innerrightmargin=0.5em,
  skipabove=0.5\baselineskip,
  skipbelow=0.5\baselineskip,
]{exampleframe}

\newenvironment{example}
  {\begin{exampleframe}\begin{exampleinner}}
  {\end{exampleinner}\end{exampleframe}}

% ---------- Macros ----------
\newcommand{\Hist}{\mathcal{H}}
\newcommand{\Poss}{\mathsf{Poss}}
\newcommand{\Spec}{\mathsf{Spec}}
\newcommand{\SpecIt}{\mathsf{\mathit{Spec}}}
\newcommand{\Obs}{\mathsf{Obs}}
\newcommand{\Ord}{\preceq}
\newcommand{\hext}{\sqsubseteq_h}
\newcommand{\hextback}{\sqsupseteq_h}
\newcommand{\In}{\mathsf{In}}
\newcommand{\Expose}{\mathsf{Expose}}

% ---------- Comments ----------
\newcommand{\jmh}[1]{\textcolor{red}{[JMH: #1]}}

% Notation conventions (for internal reference):
% - Histories: \Hist is the set of histories; elements are H, H_1, H_2.
% - Happens-before: e_1 \rightarrow e_2 is Lamport's relation on events.
% - History extension: H_1 \hext H_2 is the history-extension order.
% - Observation function: \Poss : \Hist \to 2^O.
% - Specification: \Spec = (E, \Obs, \Ord).
% - Possibility: \Poss is derived from \Obs.
% - Admissibility: \Obs : \Hist \to 2^O.
% - Outcome order: o_1 \Ord o_2 means o_2 does not contradict o_1.
% - Processes/events/outcomes: p, q (processes), e, e\' (events), o, o\' (outcomes).
\begin{document}

% ================================================================
% Note (meta): Before submission, check the PODC page limit and trim
% Applications/Related Work as needed.
% Note (meta): Ensure all claims of generalization over CALM/CAP/hierarchy have
% precise statements and proofs or citations.
\begin{abstract}
  When is coordination \emph{intrinsically required} by a distributed specification, rather than imposed by a particular protocol or implementation strategy? We give a general answer using minimal assumptions. In an asynchronous message-passing model, we represent executions as Lamport histories: collections of events partially ordered under happens-before. We abstract away from implementation mechanics and reason only about the observable outcomes that a specification admits at each history. We show that a specification admits a coordination-free implementation if and only if observable outcomes evolve monotonically as histories grow.

  This \emph{Coordination Criterion} is stated entirely at the level of specifications, independent of any particular programming language, object implementation, or protocol structure. It yields a sharp boundary between specifications that can be implemented without coordination and those for which coordination is unavoidable. The criterion provides a uniform explanation for a range of classical results, including distributed protocols and impossibility results, CAP-style consistency tradeoffs, CALM-style coordination tests, and programming-language analyses. Each can be viewed as an instance of the same underlying semantic phenomenon.
\end{abstract}


\title{The Coordination Criterion}
\author{Joseph M. Hellerstein}
\affiliation{%
  \institution{UC Berkeley \& Amazon Web Services}
  \city{Berkeley, CA}
  \country{USA}
}
\date{}
\maketitle



% ================================================================
\section{Introduction}
\label{sec:introduction}
% ================================================================

Coordination is a recurring theme in distributed computing.
Protocols such as agreement, atomic commit, and synchronous barriers ensure correctness under asynchrony and partial failure—but at a cost in latency, complexity, and failure sensitivity.
This motivates a fundamental question:

\begin{quote}
  When is coordination \emph{intrinsically necessary} to implement a distributed
  specification?
\end{quote}

Prior work has approached this question across multiple abstraction layers.
Protocol and task theory provide impossibility and hierarchy results for consensus
and atomic commitment, characterizing when processes must wait or synchronize.
At the level of shared objects, CAP relates availability under partitions to
strong guarantees such as linearizability.
At the level of programs, CALM and its successors connect coordination-freedom
to monotonicity of observable behavior.
Transactional isolation and invariant-preserving replication add yet another lens,
reasoning about coordination through anomalies and application-level correctness.

These results capture essential facets of coordination, but they are developed
within formalisms tailored to particular mechanisms, consistency models, or
programming abstractions.
This paper instead characterizes when coordination is intrinsically required
across this spectrum.

We show that coordination is a property of a specification itself,
independent of particular protocols, languages, or consistency conditions.
By formulating specifications directly over Lamport histories—sets of events partially ordered by happens-before—and a specification-defined notion of
observability, we obtain a sharp boundary theorem that applies uniformly
across settings.

The Coordination Criterion (Theorem~\ref{thm:coordination-criterion}) states that \emph{a specification admits a
  coordination-free implementation iff its observable outcomes evolve
  monotonically under history extension}.
This single criterion unifies the disparate lines of work above under a common
semantic obstruction: outcomes that can be exposed at a history but invalidated by an
admissible extension to that history.
Because it is agnostic to abstraction level, the criterion applies uniformly
across these settings.
Sufficiency shows that if the specification is monotone, an implementation can
expose any admissible outcome at a history, without pruning outcomes that remain possible
under admissible extensions of that history.
Necessity shows that if monotonicity fails, coordination is required:
implementations must prune some specification-permitted outcome that remains
possible under admissible extensions.

\parhead{A semantic lens.}
Our formulation takes a deliberately minimal view of distributed systems.
We fix only a universe of event types—external inputs, internal steps,
and message sends and receives—and require histories to be well-formed
with respect to happens-before and point-to-point messaging.
No synchrony, failure detectors, or fairness assumptions are introduced.
We make no additional operational assumptions about implementations or executions.
Instead, we reason about observability: a specification is characterized
entirely by which observable outcomes it admits at each history.
Coordination is then defined not as a mechanism,
but as the semantic necessity to eliminate outcomes
that remain admissible under causally consistent extensions.
This separation isolates coordination as a property of observable semantics,
not of the machinery that realizes them.

The payoff of this formulation is not merely unifying, but diagnostic.
When the criterion fails, coordination cannot be eliminated by alternative
protocol designs, because early outcomes may be invalidated by admissible
extensions.
When it holds, coordination-free implementations exist.
Linearizable registers fail the criterion, while global snapshots satisfy it.
This allows coordination requirements to be understood \emph{before} algorithm
design begins, and across settings where prior results had to be established
separately.

\parhead{Scope.}
We study safety-style semantic conditions on observable behavior, which we
collectively refer to as \emph{consistency}.
The Coordination Criterion characterizes when a specification admits a
coordination-free implementation under all admissible asynchronous executions,
including message delay, loss, and crashes.
Crashes are modeled implicitly by allowing histories in which a process simply stops taking internal steps or sending/receiving messages.
We deliberately abstract away from liveness concerns (e.g., termination or
wait-freedom) and failure-recovery mechanisms, which are orthogonal to the
semantic necessity of coordination.
Our goal is to identify exactly when coordination is intrinsic to a
specification.

\subsection{When Coordination is Intrinsic}

Before launching into formal definitions, we clarify the intuition behind the criterion.

\parhead{Coordination.}
We treat coordination as a semantic phenomenon rather than a protocol mechanism.
Intuitively, coordination arises when correctness forces the implementation to prune specification-permitted outcomes that remain possible under the same inputs.
An implementation is coordination-free precisely when it does not eliminate any specification-permitted outcome that remains possible under causally admissible extensions.

\parhead{Consistency and monotonicity.}
Consistency is a \emph{no-regret property of observations}: an outcome admitted given the history so far should remain compatible with all
possible extensions of that history.
A specification has this property exactly when it induces a \emph{monotone} mapping from
histories to observable outcomes, refining outcomes under extension but never
retracting them.
Our main result shows that such monotonicity is necessary and sufficient for a
coordination-free implementation.
When it fails, outcomes admissible given the history so far may later
become incompatible, forcing implementations to exclude executions and thereby
introduce coordination.

\parhead{Learning vs.\ commitment.}
At first glance, this notion of coordination may seem too strong.
Many familiar protocols appear to “rule out” outcomes simply by observing
additional events—e.g., collecting responses or votes.
The key distinction is between \emph{learning} new information by extending a
history, and making \emph{semantic commitments} that restrict which extensions
remain admissible.

As a history grows, learning may render some outcomes unrealizable—not because
the implementation forbids them, but because they are no longer consistent with
the enlarged history.
For example, once $f{+}1$ votes have arrived, outcomes that depend on observing
only $f$ votes are not realizable: no causally admissible extension of the
current history contains fewer than $f{+}1$ votes. Hence no admissible extension must be
ruled out.
Coordination arises only when correctness requires preventing outcomes that
\emph{remain causally admissible}—for instance, committing to an exact count
while additional increment events are still possible.
Counting votes is learning; fixing membership is a semantic commitment.
Only the latter constitutes coordination in our sense.

% ================================================================
\section{Computational Model}
\label{sec:model}
% ================================================================

We model executions using Lamport histories, representing distributed
executions as finite or infinite partially ordered sets of events
rather than linear traces.

To scope the space of histories, we fix disjoint sets of events:

{\setlength{\multicolsep}{2pt}% space before/after the environment
\setlength{\premulticols}{0pt}% extra space when starting multicols
\setlength{\postmulticols}{0pt}% extra space when ending multicols
\begin{multicols}{2}
  \begin{itemize}[nosep]
    \item $E_{\mathit{in}}$   — external input events,
    \item $E_{\mathit{int}}$  — internal (local) events,
    \item $E_{\mathit{send}}$ — message send events,
    \item $E_{\mathit{recv}}$ — message receive events.
  \end{itemize}
\end{multicols}}

These sets constitute the event universe of a specification.
% All histories and implementations are limited to this universe.
The partitions distinguish interface activity, internal computation,
and message-passing structure, which will play distinct roles in defining
valid histories and comparing executions with the same inputs.

\begin{definition}[History]
  A \emph{history} is a pair $H=(E,\rightarrow)$ where:
  \begin{itemize}[nosep]
    \item $E \subseteq
            E_{\mathit{in}}
            \cup E_{\mathit{int}}
            \cup E_{\mathit{send}}
            \cup E_{\mathit{recv}}$,
    \item $\rightarrow$ is a strict partial order on $E$, and
    \item for every receive event $r \in E \cap E_{\mathit{recv}}$,
          there exists a unique send event
          $s \in E \cap E_{\mathit{send}}$
          such that $s \rightarrow r$; moreover, each $s \in E \cap E_{\mathit{send}}$
          precedes at most one receive event in $E \cap E_{\mathit{recv}}$.
  \end{itemize}
  We write $\Hist_E$ for the class of all well-formed histories over $E$.
  When $E$ is fixed by the surrounding specification, we simply write $\Hist$.
\end{definition}

\noindent
% The matching relation between sends and receives is determined by
% message identity; we treat it abstractly and do not model message
% contents.

Histories need not be complete.
A history may represent an execution prefix with pending operations,
in-flight messages, or unresolved outcomes.
Messages may be delayed, reordered, or lost; a send without a matching
receive denotes a lost or indefinitely delayed message.
We impose no fairness or progress assumptions.

External input events represent activity at the system interface.
They allow us to compare executions that receive the same inputs but
differ in asynchronous scheduling:

\begin{definition}[Input projection]
  For a history $H=(E,\rightarrow)$, the \emph{input projection} of $H$,
  written $\In(H)$, is the history obtained by restricting $H$
  to its input events. The restriction of a history to its input events is itself a well-formed history.
  $
    \In(H)
    \triangleq
    \bigl(E \cap E_{\mathit{in}},
    \rightarrow \cap ((E \cap E_{\mathit{in}})
    \times
    (E \cap E_{\mathit{in}}))\bigr).
  $
\end{definition}
\noindent

History extension preserves prior events and their causal order,
adding only causally later events:
\begin{definition}[History extension]
  Given an event universe $E$ and corresponding histories $\Hist_E$,
  consider two histories
  $H_1 = (E_1,\rightarrow_1)$ and
  $H_2 = (E_2,\rightarrow_2)$.
  We write $H_1 \hext H_2$ if:
  \begin{itemize}[nosep]
    \item $E_1 \subseteq E_2 \subseteq E$,
    \item $\rightarrow_1
            = \rightarrow_2 \cap (E_1 \times E_1)$,
    \item $E_1$ is downward closed under $\rightarrow_2$, i.e., for every
          $e \in E_1$, if $e' \rightarrow_2 e$ then $e' \in E_1$.
  \end{itemize}
\end{definition}

% \parhead{Example (replicated register).}
% Consider a history \(H_1\) in which process \(p\) performs a write and sends a
% message to process \(q\), but the message has not yet been delivered.
% An extension \(H_2\) of \(H_1\) may add the corresponding receive event at \(q\),
% or may add other local events at either process, so long as all happens-before
% constraints are respected.
% Crucially, \(H_2\) cannot remove or reorder events already in \(H_1\), nor can it
% introduce new causal predecessors of existing events.

% ================================================================
\section{Specifications: Observability, Order, and Consistency}
\label{sec:obs-consistency}
% ================================================================

We take a minimal semantic view of distributed behavior.
Rather than describing how executions unfold operationally, we focus on what is
visible: which outcomes are admissible at a given history.
Histories serve only as points of reference for observable behavior; the meaning
of a specification is given by the set of outcomes it admits at each history.

\begin{definition}[Observability Function]
  For a given event universe $E$, an \emph{observability function} is a function
  $
    \Obs : \Hist_E \rightarrow \mathcal{P}(O),
  $
  where \(O\) is a set of outcomes.
  Intuitively, \(\Obs(H)\) is the set of outcomes admissible to expose at
  history \(H\).
\end{definition}
\noindent
Observability is set-valued: a specification may admit multiple outcomes at a given
history, although any concrete execution exposes at most one.
This multiplicity reflects semantic flexibility, not operational uncertainty.

To reason about compatibility of outcomes across history extension, we equip
the outcome domain with a refinement order.

\begin{definition}[Outcome Order]
  The outcome domain $O$ carries a partial order $\Ord$.
  We write $o_1 \Ord o_2$ when $o_2$ is a refinement of $o_1$.
\end{definition}
\noindent
The order $\Ord$ is part of the specification.
It does not describe execution steps, but encodes how outcomes relate
under specification-relevant refinement.
This structure will be used to define consistency over outcomes.

\begin{definition}[Specification]
  A \emph{specification} is a triple
  $\Spec = (E,\Obs,\Ord)$ where:
  \begin{itemize}[nosep]
    \item $E = (E_{\mathit{in}}, E_{\mathit{int}},
            E_{\mathit{send}}, E_{\mathit{recv}})$
          is a tuple of pairwise disjoint event sets,
          fixing the event universe,
    \item $\Obs : \Hist_E \to \mathcal{P}(O)$ is an observability function
          over well-formed histories on $E$,
    \item $\Ord$ is a partial order on outcomes $O$.
  \end{itemize}
\end{definition}
\noindent
We henceforth fix a specification $\Spec = (E,\Obs,\Ord)$ and write $\Hist$ for $\Hist_E$ when $E$ is unambiguous.

A specification determines both the space of histories
(via its event universe $E$) and the semantic constraints on observable
outcomes (via $(\Obs,\Ord)$).
Beyond the structural well-formedness of histories, it imposes no
operational constraints on execution.
All coordination requirements arise solely from the evolution of
observable outcomes under history extension.

To relate present admissibility to future evolution, we derive a
possibility operator:

\begin{definition}[Possibility (Derived)]
  \label{def:possibility-derived}
  For $H \in \Hist$, define
  $
    \Poss(H) \triangleq \bigcup_{H' \in \Hist \;:\; H \hext H'} \Obs(H').
  $
  Thus $\Poss(H)$ collects all outcomes that may arise along some well-formed
  extension of $H$.
\end{definition}

\begin{example}[Possibility vs.\ observability]
  \label{ex:counter-poss-obs}
  Consider a specification whose outcomes record the value of a monotonically
  increasing counter.
  At a history $H$ containing two increment events,
  $
    \Obs(H)=\{2\}.
  $
  Yet future extensions may perform additional increments, so
  $
    \Poss(H)=\{2,3,4,\ldots\}.
  $
  $\Poss(H)$ summarizes which outcomes remain admissible along extensions of $H$.
\end{example}

\medskip

\begin{definition}[Consistency and Contradiction]
  A set $S \subseteq O$ is \emph{consistent} if its elements admit a common refinement: i.e., there exists
  $o \in O$ such that $s \Ord o$ for all $s \in S$.
  Two outcomes \emph{contradict} if they do not form a consistent set.
\end{definition}

Consistency is atemporal: it asks whether outcomes admit a common refinement.
Future-consistency lifts this notion to history extension.

\begin{definition}[Future-Consistent Outcome]
  Let $H_1 \in \Hist$ and $o \in \Obs(H_1)$.
  We say $o$ is \mbox{\emph{future-consistent}} if for every extension
  $H_1 \hext H'$, there exists $o' \in \Obs(H')$
  with $o \Ord o'$.
  Else it is \mbox{\emph{future-inconsistent}}.
\end{definition}

The boundary between coordination-free and coordination-requiring behavior will
turn on whether every admitted outcome is future-consistent under all
extensions.
Section~\ref{sec:coordination-criterion} formalizes this as monotonicity with
respect to $\Ord$.

\subsection{Modeling the Specification}
\label{rem:faithful-observations}

The specification $\Spec=(E,\Obs,\Ord)$ embodies a modeling choice.
Its event universe $E$ determines which histories are under consideration,
while $(\Obs,\Ord)$ determine which outcomes are admissible and how they relate under extension.
The Coordination Criterion applies to the specification as defined; different
modeling choices yield different coordination requirements.

If the outcome domain or order is too coarse, genuine conflicts disappear.
For example, if $O$ contains a top element $\top$ that refines every outcome,
then all outcomes are consistent and no specification requires coordination.
If the outcome space is too fine, incidental distinctions may introduce
spurious non-monotonicity.
For example, a register specification that records the number of retry attempts,
even when retries are semantically irrelevant, may create artificial
incompatibilities under extension.
A faithful specification captures exactly the semantic commitments of interest—
neither collapsing genuine conflicts nor introducing accidental ones.
Section~\ref{sec:applications} develops natural specifications across a range of
settings.

% ================================================================
\section{Implementations and Coordination}
\label{sec:specs-and-coordination}
% ================================================================
We now connect the semantic specification above to implementations.
A specification constrains which outcomes may be exposed at each history; an implementation determines which histories may arise under given inputs and which outcomes it may expose at those histories.
The question is not whether coordination is used, but where it is
intrinsic to the specification.

\parhead{Asynchronous Model and Admissible Histories.}
Fix a specification $\Spec=(E,\Obs,\Ord)$.
We work in the standard asynchronous message-passing model over the
event universe $E$.
Executions are parameterized by a prefix of external inputs.
For a fixed input history $H_{\mathit{in}} \in \Hist_E$, the environment
determines which histories are possible by extending
$H_{\mathit{in}}$ with additional external inputs and asynchronous
scheduling, including message delay or loss and process crashes,
without imposing fairness or progress assumptions.

\begin{definition}[Admissible Histories]
  \label{def:admissible}
  For a given input history prefix $H_{\mathit{in}} \in \Hist_E$, define
  \[
    \mathcal{A}(H_{\mathit{in}})
    \triangleq
    \{\, H \in \Hist_E \mid H_{\mathit{in}} \hext \In(H) \,\}.
  \]
  These are exactly the well-formed histories over $E$ consistent with
  the same external inputs, under asynchrony and causality alone.
  The set $\mathcal{A}(H_{\mathit{in}})$ is upward-closed under history
  extension; additional inputs remain admissible in extensions.
\end{definition}

\begin{definition}[Implementation]
  \label{def:implementation}
  An implementation $I$ describes
  (i) which histories over $E$ may arise under a given pattern of
  external inputs and
  (ii) which outcomes it may expose at those histories.
  Formally, $I$ consists of:
  \begin{itemize}[nosep]
    \item for each input history prefix $H_{\mathit{in}} \in \Hist_E$,
          a set of realizable histories
          $\mathcal{R}_I(H_{\mathit{in}}) \subseteq \Hist_E$, and
    \item an outcome-exposure map
          $\Expose_I : \Hist_E \to \mathcal{P}(O)$,
          where $\Expose_I(H)$ is the set of outcomes that $I$ may expose
          at history $H$.
  \end{itemize}
  An implementation is \emph{correct} for $\Spec=(E,\Obs,\Ord)$ if
  $\Expose_I(H)\subseteq \Obs(H)$ for all $H \in \Hist_E$.
\end{definition}
\noindent
The possibility operator of Section~\ref{sec:obs-consistency}
ranges over all well-formed extensions.
For coordination, we refine it by fixing the external inputs and
restricting to extensions consistent with them.

\begin{definition}[Specification-relative possibility]
  Fix a specification $\Spec = (E, \Obs,\Ord)$ and an input history
  prefix $H_{\mathit{in}}$.
  For a history $H \in \mathcal{A}(H_{\mathit{in}})$, define
  \[
    \Poss_{H_{\mathit{in}}}(H)
    \triangleq
    \bigcup_{\substack{H' \in \mathcal{A}(H_{\mathit{in}})\\ H \hext H'}} \Obs(H').
  \]
\end{definition}
\noindent
This is the set of outcomes that remain possible under the specification
along some causally admissible extension consistent with the same
external inputs.

We restrict attention to implementations within the asynchronous model:
for each input prefix $H_{\mathit{in}}$, we focus on realizable histories
$
  \mathcal{R}_I(H_{\mathit{in}}) \subseteq \mathcal{A}(H_{\mathit{in}}).
$
For such an implementation, the outcomes it may still expose from a
history $H$ (without changing the external inputs) are given by:

\begin{definition}[Implementation-relative possibility]
  For an implementation $I$, define
  \[
    \Poss^{I}_{H_{\mathit{in}}}(H)
    \triangleq
    \bigcup_{\substack{H' \in \mathcal{R}_I(H_{\mathit{in}})\\ H \hext H'}} \Expose_I(H').
  \]
\end{definition}

The condition we impose next—possibility preservation—captures the
absence of coordination.

\begin{definition}[Coordination-Free Implementation]
  \label{def:coordfree}
  Fix a specification $\Spec = (E, \Obs,\Ord)$.
  An implementation $I$ is \emph{coordination-free} if, for every input history
  prefix $H_{\mathit{in}}$:
  \begin{enumerate}[nosep]
    \item \emph{(Correctness)}
          For every $H \in \mathcal{R}_I(H_{\mathit{in}})$,
          $\Expose_I(H) \subseteq \Obs(H)$.
    \item \emph{(Possibility preservation)}
          For every $H \in \mathcal{R}_I(H_{\mathit{in}})$,
          $
            \Poss^{I}_{H_{\mathit{in}}}(H)
            =
            \Poss_{H_{\mathit{in}}}(H).
          $
  \end{enumerate}
\end{definition}
\noindent
A coordination-free implementation may change \emph{how} histories extend
(e.g., via retries or internal messages), but it never prevents
outcomes that remain possible under the same external inputs.

\begin{example}[Replicated Register Specifications]
  \label{ex:register-specs}
  Consider histories in which processes perform reads and writes on a
  single logical register replicated at two nodes.
  This example illustrates how different choices of \emph{observability}, over
  the same underlying behaviors, determine which outcomes are admissible at a
  given history.

  Let outcomes record the sequence of completed reads and writes annotated with
  arguments and return values, ordered by prefix extension.
  We define two observable specifications
  $\Spec_{\mathit{avail}} = (E, \Obs_{\mathit{avail}}, \Ord)$ and
  $\Spec_{\mathit{lin}} = (E, \Obs_{\mathit{lin}}, \Ord)$ over the same outcome
  domain and order.
  The first describes a highly available register:
  after history $H$, a read may return the initial value or any value written in
  the causal past of that read
  (i.e., written by an event that happens-before the read).
  The second describes a linearizable register:
  $\Obs_{\mathit{lin}}(H)$ contains exactly those sequences that admit a
  linearization respecting real time.
  These two specifications differ only in the outcomes they admit, yet we will see they have sharply different coordination
  requirements (\S\ref{sec:registers}).
\end{example}

\begin{remark}[Coordination vs.\ Nondeterminism]
  A specification may admit multiple outcomes for the same history, and an
  implementation may nondeterministically choose among them.
  Such choice does not constitute coordination in our sense.
  The distinction is not whether, for a fixed history $H$, an implementation
  chooses among outcomes in $\Obs(H)$, but whether correctness forces it to avoid
  exposing future-inconsistent outcomes.
\end{remark}

\begin{example}[Mechanisms that Preserve vs.\ Restrict Observations]
  Not all protocol mechanisms constitute coordination.
  Some merely refine which outcome is eventually exposed, while others
  eliminate outcomes that the specification still admits.

  Consider a request--response service whose outcome records whether a
  message has been received.
  Before an acknowledgment arrives, both “received” and
  “not yet received” may lie in $\Obs(H)$.
  Retrying does not remove either outcome from $\Poss_{H_{\mathit{in}}}(H)$; it may influence which admissible outcome is exposed, but it prunes none.

  By contrast, consider a membership specification whose outcomes are sets of
  processes.
  Suppose $\Obs(H)=\{M_1,M_2\}$ and there exists an extension $H'$
  with $\Obs(H')=\{M_2\}$.
  Then $M_1$ is future-inconsistent at $H$.
  Exposing $M_1$ eliminates the specification-permitted outcome corresponding to $M_2$, yielding
  $
    \Poss^{I}_{H_{\mathit{in}}}(H) \subsetneq \Poss_{H_{\mathit{in}}}(H).
  $
  This elimination is coordination.
  Subsequent examples show how this distinction arises in familiar consistency
  conditions.
\end{example}

% ================================================================
\section{The Coordination Criterion}
\label{sec:coordination-criterion}
% ================================================================

We distinguish the causal structure supplied by the environment (happens-before)
from the semantic constraints a specification imposes on observable outcomes.
We now characterize exactly when those constraints can be realized without
coordination.

\begin{definition}[Monotone Specification]
  A specification $\Spec=(E,\Obs,\Ord)$ is \emph{monotone} if for all
  $H_1,H_2 \in \Hist_E$ with $H_1 \hext H_2$ and all
  $o \in \Obs(H_1)$, there exists $o' \in \Obs(H_2)$
  such that $o \Ord o'$.
\end{definition}
Monotonicity is a no-regret condition on observable behavior: once an outcome is
admitted, every extension admits a compatible refinement.
Non-monotonicity is witnessed by a future-inconsistent outcome—admitted
at a prefix but incompatible with all outcomes admitted by some extension.
Such witnesses force elimination of specification-permitted possibilities,
i.e., coordination.

\begin{remark}
  A specification is defined on all histories, not only complete executions.
  When it is monotone, extending a history can only refine admissible outcomes
  in the order $\Ord$, giving stable semantics to early observations.
\end{remark}

\begin{theorem}[Coordination Criterion]\label{thm:coordination-criterion}
  A specification $\Spec=(E,\Obs,\Ord)$ admits a coordination-free
  implementation if and only if it is monotone.
\end{theorem}

\begin{example}[Replicated register revisited]
  This example isolates future-inconsistency in a familiar specification.
  Consider the replicated register specifications from
  Example~\ref{ex:register-specs}, with outcomes taken to be sequences of
  completed reads and writes ordered by prefix extension.
  Let $H_1$ be a history in which a read is concurrent with a write of value $1$,
  with neither event yet completed.
  At this prefix, completing the read before the write yields the outcome
  $
    o = \langle \mathsf{read}(0) \rangle
  $,
  which lies in both $\Obs_{\mathit{avail}}(H_1)$ and $\Obs_{\mathit{lin}}(H_1)$.

  Now extend $H_1$ to a history $H_2$ in which the write is delivered and
  completed before the read.
  Under $\Spec_{\mathit{avail}}$, there exists an outcome
  $o' \in \Obs_{\mathit{avail}}(H_2)$ such that $o \Ord o'$.
  Under $\Spec_{\mathit{lin}}$, for every $o' \in \Obs_{\mathit{lin}}(H_2)$,
  $o$ and $o'$ contradict, since every $o'$ requires the read to return $1$.
  Thus $\Spec_{\mathit{lin}}$ is non-monotone: it admits an outcome at $H_1$
  that is future-inconsistent.
  Replication makes the same inconsistency relevant across replicas.
\end{example}

\subsection{Proof Sketch}

We work in the asynchronous message-passing model of
Section~\ref{sec:model}.
Implementations must satisfy correctness:
$\Expose_I(H) \subseteq \Obs(H)$.
We sketch the argument; a full construction appears in
Appendix~\ref{app:coordination-criterion-proof}.

\parhead{Sufficiency.}
Assume the specification $\Spec=(E,\Obs,\Ord)$ is monotone.
We construct an implementation $I$ that is correct and preserves
specification-relative possibility.

Fix an input prefix $H_{\mathit{in}}$.
For each $H \in \mathcal{A}(H_{\mathit{in}})$, let
$\mathcal{R}_I(H_{\mathit{in}}) \subseteq \mathcal{A}(H_{\mathit{in}})$,
% consist of well-formed histories
% consistent with the same inputs, 
and let
$\Expose_I(H) \subseteq \Obs(H)$ be chosen nondeterministically.
Correctness holds by construction.
Because the specification is monotone, every outcome
$o \in \Obs(H)$ is future-consistent: for every
$H' \hext H$ there exists $o' \in \Obs(H')$ with $o \Ord o'$.
Exposing $o$ at $H$ therefore does not eliminate any outcome
admitted along any admissible extension.
Hence for every reachable $H$,
$
  \Poss^{I}_{H_{\mathit{in}}}(H)
  =
  \Poss_{H_{\mathit{in}}}(H).
$
Thus $I$ is coordination-free.

\vspace{0.5em}
\parhead{Necessity.}
Assume the specification is non-monotone.
Then there exist histories $H_1 \hext H_2$ and an outcome
$o_1 \in \Obs(H_1)$ such that
$o_1$ contradicts every $o' \in \Obs(H_2)$.

Let $H_{\mathit{in}} \triangleq \In(H_1)$.
Then
$
  H_{\mathit{in}} \hext H_1 \hext H_2,
$
so $H_1,H_2 \in \mathcal{A}(H_{\mathit{in}})$ and
$o_1 \in \Poss_{H_{\mathit{in}}}(H_1)$.
Suppose, for contradiction, that there exists a coordination-free
implementation $I$ for input prefix $H_{\mathit{in}}$.
Then
$
  \Poss^{I}_{H_{\mathit{in}}}(H_1)
  =
  \Poss_{H_{\mathit{in}}}(H_1).
$
Since $o_1 \in \Obs(H_1)$ and $H_1 \in \mathcal{R}_I(H_{\mathit{in}})$,
correctness allows $I$ to expose $o_1$ at $H_1$.
However, along the admissible extension $H_2$,
every outcome in $\Obs(H_2)$ contradicts $o_1$.
Preserving all specification-permitted possibilities at $H_1$
therefore requires allowing outcomes in $\Obs(H_2)$ to remain possible,
yet none are compatible with $o_1$.
Thus
$
  \Poss^{I}_{H_{\mathit{in}}}(H_1)
  \subsetneq
  \Poss_{H_{\mathit{in}}}(H_1),
$
contradicting coordination-freedom.
Hence no coordination-free implementation exists.

\parhead{Tightness.}
The criterion is tight.
Monotonicity is exactly the condition that rules out future-inconsistent
outcomes.
If one weakens it, then there exists a specification admitting a future-inconsistent
outcome, and the necessity argument above applies.
A formal minimality argument appears in Appendix~\ref{app:minimality}.


% ================================================================
\section{Applications of the Coordination Criterion}
\label{sec:applications}
% ================================================================
We illustrate the Coordination Criterion through a sequence of case studies,
from mutable state to replication, agreement, and declarative programs.
% 
% \parhead{Unifying pattern.}
% Across examples, coordination is required exactly when a specification is
% non-monotone: when there exist histories $H_1 \hext H_2$ and an outcome
% $o \in \Obs(H_1)$ such that no outcome in $\Obs(H_2)$ extends $o$ under $\Ord$.
% Such an outcome is \emph{future-inconsistent}.
By the Coordination Criterion, non-monotonicity precludes
coordination-free implementations. We use future-inconsistent outcomes as a concrete
witness of non-monotonicity throughout.

% ------------------------------------------------
\subsection{Mutable Variables: Registers}
\label{sec:registers}
% ------------------------------------------------
We begin with the simplest mutable object: a register with reads and writes, and
no auxiliary metadata such as versions, timestamps, or logs.
% Registers serve as a running witness across multiple coordination phenomena.

\parhead{$\SpecIt$ sketch.}
Histories consist of read and write events on a single register.
Outcomes are sequences of completed reads and writes annotated with return values.
% For a history $H$, outcomes admitted along some extension of $H$ capture
% all sequences realizable by a causally consistent evolution.
The observation function $\Obs(H)$ restricts these to outcomes admitting a
linearization consistent with real time.
The outcome order $\Ord$ is prefix extension on these sequences.

\parhead{Non-monotonicity.}
A read must return the value of the write that \emph{immediately precedes} it in
the chosen linearization (or the initial value if no write precedes it).
Consider a prefix history $H_1$ with initial value $0$, a write $w$ of value $1$,
and a read $r$, where $w$ and $r$ are concurrent (neither $w \rightarrow r$ nor $r \rightarrow w$).
Then $\Obs(H_1)$ includes both outcomes
$\langle \mathsf{read}(0)\rangle$ and $\langle \mathsf{read}(1)\rangle$,
corresponding to the two possible linearizations.
Now extend $H_1$ to a history $H_2$ by resolving the race in real time, so that
$w$ completes before $r$ (i.e., $w \rightarrow r$).
In $\Obs(H_2)$, every real-time--respecting linearization must place $w$ before
$r$, so the outcome $\langle \mathsf{read}(0)\rangle$ is incompatible with
$\Obs(H_2)$.
Thus $\langle \mathsf{read}(0)\rangle$ is \emph{future-inconsistent}:
observable at $H_1$ but admitting no $\Ord$-consistent continuation at $H_2$.
This non-monotonicity shows that even a local read can force coordination—semantically,
before any replication, failures, or network effects are introduced.
% ------------------------------------------------
\subsection{Replication, Partitions, and Waiting (CAP)}
% ------------------------------------------------

Replication makes the need for coordination externally visible.
It does so not by changing the register semantics, but by exposing incompatible
outcomes across replicas.

\parhead{$\SpecIt$ refinement.}
We reuse the same register specification as above, but histories now include send and receive events that propagate writes between
replicas, with causal order induced by message delivery.
A network partition may emerge at some causal cut of a history, after which messages sent
across the partition are never received.
We consider only histories that respect such partitions, as formalized in Appendix~\ref{app:cap-formal}. This is a restriction on admissible histories $\mathcal{A}(H_{in})$, not on the specification’s outcome semantics.
Crucially, the observation function $\Obs$ is unchanged: outcomes must still admit
a real-time--respecting linearization of all completed read and write events.

\parhead{Operational consequence.}
Consider a prefix history $H_1$ in which replica $p$ issues a write of value $1$, while a read at replica $q$ is concurrent with that write.
At $H_1$, both return values are semantically admissible in the
specification.
If the read at $q$ completes immediately, it must commit to one of these values.
However, there exist causally admissible extensions—those in which a
network partition isolates $p$ from $q$—in which one of these commitments is future-inconsistent.
Which commitment is invalidated depends on events that $q$ cannot locally
observe.

\parhead{Diagnosis (CAP).}
Replication does not fundamentally change register semantics: the specification admits the same
future-inconsistent outcomes as in the single-register case.
What changes is how those inconsistencies can be avoided.
Doing so requires coordination to enforce one linearization choice and prevent
conflicting observations, which in a
replicated setting entails communication.
When a partition prevents that communication, an implementation must either
withhold outcomes to preserve correctness, becoming unavailable, or remain
available and risk exposing inconsistent observations.
This is CAP in semantic form.
A formal treatment appears in Appendix~\ref{app:cap-formal}.

% ------------------------------------------------
\subsection{Consensus and Agreement Protocols}
\label{sec:consensus}
% ------------------------------------------------

Consensus is sometimes presented as a way to ``fix'' replicated registers.
From the perspective of the Coordination Criterion, this is misleading.
Consensus does not remove the non-monotonicity of underlying mutable state;
it coordinates \emph{who} may expose observations, and \emph{when}.

\parhead{World closure is non-monotone.}
Authority selection concerns \emph{who} may expose observations.
We write $\Obs_{\textsf{auth}}(H)$ for the set of admissible authority outcomes at
history $H$, where an authority outcome is a set of candidate authority
configurations; $\Ord$ is defined as reverse set inclusion.
At a given history, $\Obs_{\textsf{auth}}(H)$ may admit multiple outcomes,
including one in which both configurations $A$ and $B$ remain possible, as well
as outcomes selecting a single configuration (e.g., $\{A\}$ or $\{B\}$).
Crucially, $\Obs_{\textsf{auth}}$ has no history-forced observation: the history
never determines which singleton refinement is correct, yet progress requires
exposing one authority.
If $\{A\}$ is exposed, there exists a history extension in which
$\Obs_{\textsf{auth}}(H') = \{\{B\}\}$,
so every outcome admitted there contradicts the earlier commitment.
Thus $\Obs_{\textsf{auth}}$ is non-monotone.
See Appendix~\ref{app:consensus-detail}.

\parhead{Value selection within a closed world.}
Value selection concerns \emph{when} outcomes become visible.
Once an authority configuration is fixed, we write $\Obs_{\textsf{val}}(H)$ for
the admissible value observations under that authority.
Unlike authority selection, $\Obs_{\textsf{val}}$ admits only history-forced
observations.
Before sufficient evidence appears, $\Obs_{\textsf{val}}(H)$ may expose no value;
this waiting is purely causal, preserving all admissible extensions.
When a value is exposed, every admissible extension is compatible with it.
Accordingly, $\Obs_{\textsf{val}}$ refines monotonically under history extension.
See Appendix~\ref{app:consensus-detail}.

\parhead{Diagnosis.}
Consensus does not eliminate non-monotonicity; it \emph{localizes} it by
coordinating world closure—fixing \emph{who} may speak.
After closure, observable outcomes appear only \emph{when} a history-forced,
monotone condition is met.

% The register-like state manipulated internally by participants remains
% non-monotone if observed directly.
% Agreement protocols restrict observability so that only a single chain of commitments is ever exposed, ensuring monotonic observable behavior despite
% non-monotone internal state. 

% ------------------------------------------------
\subsection{CALM}
% ------------------------------------------------

CALM applies the same semantic criterion to
declarative programs rather than shared objects.

\parhead{$\SpecIt$ sketch.}
Histories are executions of relational transducers.
Outcomes are output fact sets, ordered by set inclusion.
For a history $H$, $\Obs(H)$ captures the output fact sets
admissible at that prefix under the program’s logical semantics.

\parhead{Diagnosis.}
CALM exposes the same semantic boundary at the level of programs rather than
objects.
Monotone logic programs admit only growth in observable sets of output facts, while
non-monotone programs (e.g., with negation or aggregates) may require
retracting previously derived facts as histories extend, corresponding directly to
non-monotonicity of $\Obs$.

The CALM theorem follows immediately: monotone programs admit coordination-free
distributed evaluation, while non-monotone programs intrinsically require
coordination.
Formal definitions and proofs appear in Appendix~\ref{app:calm-formal}.


% ================================================================
\section{Related Work}
% ================================================================

A long line of work in distributed computing characterizes coordination in terms
of epistemic or operational requirements.
Knowledge-based approaches show that certain coordination tasks require common
knowledge or its variants~\cite{halpern1990knowledge,neiger1993simultaneous,neiger1999knowledge},
while task-solvability and hierarchy results characterize problems that can be
solved with given failure and progress assumptions
\cite{fischer1985impossibility,herlihy1991waitfree,herlihy1999topological,saks2000set}.

Such assumption strengthenings can be represented in our model by restricting which
outcomes remain possible or observable.
Our focus, however, is different.
Rather than fixing a desired semantics and strengthening assumptions to realize it,
we treat the specification as given and ask whether its semantics
intrinsically require coordination.
The Coordination Criterion provides this diagnosis independent of protocol
design or computational power.

Within this semantic perspective, our work is closest in spirit to the CALM line of
research in declarative networking, which connects coordination-freedom to
monotonicity in distributed computation.
Across this literature—ranging from logic programs and relational
transducers~\cite{hellerstein2010declarative,ameloot2013relational,ameloot2015weaker},
through relation-to-relation semantic mappings~\cite{baccaert2026spectrum}, to
ordered input--output specifications~\cite{li2025coordinationfree}—coordination-freedom
is characterized relative to semantic domains and admissibility assumptions that refine or restrict the standard asynchronous message-passing model.

By contrast, our framework makes only the assumptions common to all distributed
systems.
Using Lamport histories as the semantic domain, we model specifications
abstractly via admissible histories and observable outcomes ordered by refinement.
This minimal formulation yields a general diagnostic criterion for when
coordination is unavoidable, independent of program model, language, or
exogenous assumptions.
Consequently, the Coordination Criterion applies directly to classical
distributed objects, tasks, and consistency conditions
(\S \ref{sec:applications}, Appendix~\ref{sec:additional-applications}).

Brewer’s conjecture and the CAP theorem identify tradeoffs between availability and
strong consistency~\cite{brewer2000towards,gilbert2002cap}.
Traditional formulations fix both a notion of availability and a specific
consistency condition such as linearizability.
Our framework recovers CAP-style impossibility results as direct consequences of
the non-monotonicity of the corresponding specifications, rather than from
availability axioms or failure assumptions.

Conflict-free replicated data types (CRDTs) provide a disciplined implementation
approach to highly available replication by restricting updates to monotone,
inflationary operations~\cite{shapiro2011crdt}.
From our perspective, CRDTs occupy a well-behaved subspace of the monotone
specifications identified by the Coordination Criterion.
Our result characterizes the semantic boundary itself, rather than prescribing a
particular implementation discipline.

Additional connections to the literature in
database systems and programming languages are discussed in Appendix~\ref{sec:extended-related-work}.

% ================================================================
\section{Conclusion}
% ================================================================
Coordination has traditionally been studied through specific mechanisms or
particular impossibility results.
What has been missing is a semantic diagnostic that explains
\emph{when coordination is intrinsically required by a specification itself},
independent of protocol structure or failure assumptions.

The Coordination Criterion provides such a diagnostic.
Using only Lamport histories and observable outcomes, it characterizes
coordination as a semantic obstruction: a specification requires coordination
exactly when its observable outcomes are non-monotone under history extension,
forcing implementations to exclude causally admissible executions.

The power of this minimalist criterion lies in its reuse.
Across multiple case studies (\S\ref{sec:applications}, Appendix~\ref{sec:additional-applications}),
the same semantic test explains coordination in mutable registers, replicated
storage under partition, agreement protocols, snapshots, transactional isolation,
invariant confluence, and declarative programs.
Rather than reproving existing results, the criterion provides a uniform method
for analyzing specifications across disparate literatures.

Seen through this lens, familiar boundary results fall into place.
CAP identifies a concrete manifestation of non-monotonicity: linearizable
replicated registers expose outcomes that become incompatible across partitions.
CALM identifies another: monotone declarative programs preserve observable
outcomes under extension, while non-monotone ones require coordination.
Both are instances of the same underlying semantic phenomenon.

Crucially, the diagnostic is precise.
Monotonicity is defined relative to an explicit choice of possibility function,
observability function, and outcome order.
Any refinement sufficient to recover coordination-freedom can be expressed by
adjusting this semantic triple; beyond this boundary, coordination is unavoidable.

Our focus has been on safety-style conditions on observable behavior.
Orthogonal work on coordination-free liveness and free termination
\cite{power2025freetermination} addresses progress guarantees.
Together, these directions suggest a unified view of coordination as a semantic
resource governing when safe commitment is possible.


% ================================================================
\section*{Acknowledgments}
% ================================================================

% Thanks to Peter Alvaro, Natacha Crooks, Chris Douglas, Tyler Hou, Martin Kleppmann, Paris Koutris, Edward Lee,
% Shulu Li, David Chu McElroy, Sarah Morin and Dan Suciu for helpful feedback.
We acknowledge the use of AI-based language tools to assist with
drafting and revising the exposition; all technical content and claims
remain the responsibility of the authors.

\appendix

\section{Detailed Case Studies}
\label{sec:additional-applications}
We illustrate the reach of the Coordination Criterion by instantiating it on familiar distributed objects, tasks, consistency models, and programming abstractions. Rather than
reproving classical theorems, we show how a single semantic condition on
specifications pinpoints where coordination is and is not intrinsically
required.

\subsection{Linearizable Registers: Base Specification}
\label{app:register-spec}

We begin by fixing a base specification for read--write registers, which will be
reused in both the CAP and consensus analyses.

\parhead{$\SpecIt$ sketch.}
Histories consist of invocation and response events for read and write actions on
a single logical register, with real-time order induced by these events.
Outcomes are sequences of actions annotated with return values; an
action is completed when its response event occurs.

For a history $H$, $\Poss(H)$ is the set of all such completed-event sequences
realizable by some causally consistent extension of $H$.
The observation function $\Obs_{\mathit{lin}}(H)$ restricts these to outcomes
admitting a linearization consistent with real time.
The outcome order $\Ord_{\mathit{lin}}$ is prefix extension on these sequences.

As shown in Section~\ref{sec:applications}, this specification is non-monotone:
it admits a read outcome that is \emph{future-inconsistent}, committing to a
predecessor write that may be invalidated by a causally admissible history
extension.

% ================================================================
\subsection{CAP Revisited}
\label{app:cap-formal}
% ================================================================

To discuss CAP formally within our semantic framework, we instantiate a
replicated-register setting whose observable outcomes correspond to linearizable
read--write behavior, model partitions via constraints on message delivery, and
capture availability using a semantic notion of maximal availability under such
constraints.

\parhead{Replication and histories.}
We consider an asynchronous message-passing system in which the register is
replicated at multiple processes.
Histories extend those of Appendix~\ref{app:register-spec} with message send and
receive events propagating writes between replicas.

Replication introduces no new semantic requirements: linearizability is still
defined over the single logical register. Formally, we reuse the same register
specification $\Spec_{\mathit{lin}}=(\Poss,\Obs_{\mathit{lin}},\Ord_{\mathit{lin}})$,
now interpreted over histories that include message events.

\begin{definition}[Partition Pattern]
  A \emph{partition pattern} $P$ is a constraint on message delivery that
  specifies which send--receive events are permitted after a given cut of a
  history.
  A history $H$ is said to \emph{respect} $P$ if it contains no message delivery
  events forbidden by $P$.
\end{definition}
\noindent
Partition patterns restrict the environment’s admissible extensions, thereby
constraining $\Poss$, while leaving the observation function $\Obs$ and outcome
order $\Ord$ fixed.

\begin{definition}[Maximal Availability Under Partitions]
  \label{def:maximal-availability}
  Fix a specification $\Spec = (\Poss, \Obs, \Ord)$ in the asynchronous model above.
  Let $P$ range over partition patterns and, for a prefix history $H_i$, let
  $\mathsf{Ext}_P(H_i)$ denote the causally consistent extensions $H$ with
  $H_i \hext H$ that respect $P$.
  An implementation $I$ of $\Spec$ is \emph{maximally available under partitions}
  if for every $H_i$, $P$, and client invocation $e \in H_i$, whenever there
  exists some $H \in \mathsf{Ext}_P(H_i)$ such that $\Obs(H) \neq \emptyset$ and
  $e$ completes in $H$, there exists an execution
  $H^* \in \mathsf{Ext}_P(H_i)$ of $I$ such that $\Obs(H^*) \neq \emptyset$ and
  $e$ completes in $H^*$.
\end{definition}

\parhead{A semantic witness under partition.}
Fix a prefix history $H_i$ containing a write of value $1$ at process $p$ that is
concurrent with a read invocation at process $q$.
Let $P$ be a partition pattern whose cut occurs after the send of $p$'s write and
forbids any subsequent delivery of messages from $p$ to $q$ (but permits local
steps at both processes).
Consider extensions in $\mathsf{Ext}_P(H_i)$ in which the read at $q$ completes.

At $H_i$, both $\mathsf{read}(0)$ and $\mathsf{read}(1)$ are semantically
admissible under $\Spec_{\mathit{lin}}$.
Under $P$, however, process $q$ cannot receive evidence of the write at $p$.
If the read returns $1$, the resulting completed-event sequence is not realizable
by any extension respecting $P$, hence lies outside $\Poss(H)$ for all
$H \in \mathsf{Ext}_P(H_i)$ in which the read completes.
If the read returns $0$, there exist admissible extensions (respecting $P$) in
which real-time order places the write before the read, in which case no
real-time--respecting linearization can justify returning $0$.
In either case, completing the read exposes an outcome that is
\emph{future-inconsistent} with respect to partition-respecting extensions.

Equivalently, $(H_i,P)$ is a semantic witness of unavailability: any
partition-respecting completion yields $\Obs_{\mathit{lin}}(H)=\emptyset$.

\parhead{Diagnosis (CAP).}
The role of $P$ is to formalize local observability: after the cut, $p$ and $q$
can only rule out futures using information available within their partition.
Avoiding divergent non-monotone commitments would require excluding some
partition-respecting continuations in a coordinated way, which would entail
communication across the forbidden deliveries.
Maximal availability forbids such exclusion by waiting: if any
partition-respecting extension admits completion with some observable outcome,
the implementation must complete.

\begin{corollary}[CAP]
  In the asynchronous model above, no implementation of a replicated register can
  satisfy linearizable read--write consistency while remaining correct on all
  causally consistent histories and maximally available under partitions
  (Definition~\ref{def:maximal-availability}).
\end{corollary}

\noindent
This recovers the CAP tradeoff as a consequence of the non-monotonicity of
$\Spec_{\mathit{lin}}$ together with the semantic constraint that partitions
restrict which extensions remain causally admissible.

% ================================================================
\subsection{Consensus and Agreement: Authority Closure then Value Exposure}
\label{app:consensus-detail}
% ================================================================

This appendix instantiates a specification for agreement protocols that matches
the body discussion.
Agreement proceeds in alternating phases:
(i) a \emph{world-closure} step that fixes an authority configuration (who may
expose observations), followed by
(ii) a value-exposure phase in which decisions are revealed under that authority.
The key point is that non-monotonicity—and hence coordination—arises only in
world closure, not in value exposure.

\parhead{$\SpecIt$ sketch.}
Fix a finite population $\Pi$ and a value domain $V$ with $|V|\ge 2$.
Histories include message sends/receives, proposals, and internal protocol events.
Externally observable events are:
\begin{itemize}[nosep]
  \item authority-selection events produced by some membership/leader-election
        mechanism, and
  \item decision-exposure events $\mathsf{decide}(i,v)$, indicating that value
        $v$ has been exposed for slot $i$.
\end{itemize}
Intermediate evidence (votes, acks, retries) appears only in histories, not in
outcomes.

\parhead{Outcome domain.}
Outcomes expose only:
(i) the sequence of authority configurations that have been publicly established,
and
(ii) the values decided \emph{under the currently active authority}.
Formally, let $\mathcal{A}$ be the space of authority configurations and let $I$
be an index set of slots.
An outcome has the form
$
  o = (A, m),
$
where:
\begin{itemize}[nosep]
  \item $A \in \mathcal{A}^*$ is a finite sequence of authority configurations
        (epochs or views), and
  \item $m : I \rightharpoonup V$ is a partial function mapping slots to values,
        representing decisions made under the \emph{most recent} authority in $A$.
\end{itemize}

Well-formed outcomes satisfy the following invariant:
\emph{all decisions in $m$ are made under the last authority in $A$}.
Conceptually, a change in authority resets the decision context.

\parhead{Outcome order.}
We order outcomes by phase-respecting extension:
\[
  (A_1,m_1)\;\Ord\;(A_2,m_2)
  \quad\text{iff}\quad
  \begin{cases}
    A_1 \preceq_{\mathrm{pref}} A_2 \ \text{and}\ m_1 = \emptyset, & \text{(authority extension)} \\
    A_1 = A_2 \ \text{and}\ m_1 \subseteq m_2,                     & \text{(value extension)}
  \end{cases}
\]
where $\preceq_{\mathrm{pref}}$ is prefix order on sequences and
$m_1 \subseteq m_2$ denotes partial-map extension
(same values on existing slots, possibly more slots).

Intuitively, outcomes evolve in a series--parallel structure:
first by extending the authority history,
and then—once authority is fixed—by monotonically adding value decisions.
Authority changes delimit eras of public commitment; values decided under one
authority are not carried across authority changes.

\parhead{Observations.}
Let $\mathsf{AuthPoss}(H)\subseteq\mathcal{A}$ be the set of authority
configurations still causally admissible at history $H$.
Let $\mathsf{Dec}(H)$ be the set of decision-exposure events
$\mathsf{decide}(i,v)$ appearing in $H$.

An outcome $(A,m)$ is in $\Obs(H)$ iff:
\begin{enumerate}[nosep]
  \item $A$ is a prefix of some authority sequence consistent with $\mathsf{AuthPoss}(H)$,
        i.e., each extension step in $A$ was causally admissible when chosen, and
  \item for every $i \in \mathrm{dom}(m)$, a corresponding $\mathsf{decide}(i,m(i))$
        event appears in $H$ \emph{after} the last authority in $A$ is established.
\end{enumerate}
No outcomes expose votes, partial quorums, tentative state, or internal protocol variables.

\parhead{Where non-monotonicity arises.}
Authority selection is non-monotone.
There exist prefix histories $H_1$ in which multiple next-authority extensions
$A\cdot a$ and $A\cdot a'$ are causally admissible, and extensions $H_2$ in which
only one remains valid.
Thus, committing to a particular authority at $H_1$ can be invalidated by a
causally admissible extension.
Equivalently, authority selection admits observable outcomes that are
\emph{future-inconsistent}.
Preventing such outcomes requires excluding admissible extensions—exactly
coordination in the sense of the Coordination Criterion.

\parhead{Why value exposure is monotone.}
Conditioned on a fixed authority sequence $A$, all publicly observable decisions
occur under that authority.
Adding further decisions extends $m$ monotonically, and no history extension can
invalidate a previously exposed decision.
Thus value exposure is monotone with respect to $\Ord$; coordination is not
required in this phase.

\parhead{Slot assignment.}
The specification abstracts over how decisions are assigned to slots.
Once an authority configuration is fixed, the mapping from proposals to slots is
resolved either:
\begin{enumerate}
  \item \label{it:slot1} by a deterministic convention fixed by the authority
        (e.g., per-replica ownership as in Mencius~\cite{mao2008mencius}), or
  \item \label{it:slot2} by an internal coordination mechanism within the authority
        (e.g., leader serialization in Multi-Paxos~\cite{lamport2001paxos}).
\end{enumerate}

In case (\ref{it:slot1}), slot assignment is monotone by construction.
In case (\ref{it:slot2}), coordination is required, but it is internal to the authority
and does not affect the externally observable monotonicity of value exposure.
Our analysis applies to both cases.

\parhead{Summary.}
Agreement protocols do not eliminate non-monotonicity of underlying mutable
state.
They use coordination to control \emph{who} may expose observations (authority
selection) and \emph{when} value exposure may occur (after a quorum of votes is collected).
By enforcing a strict separation between authority closure and value exposure,
they ensure that externally observable behavior is monotone, even though the
internal state that produces it is not.

% ------------------------------------------------
\subsection{CALM Revisited}
\label{app:calm-formal}
% ------------------------------------------------

This appendix makes explicit how the CALM principle arises as a special case of
the Coordination Criterion.
Our goal is not to reprove CALM, but to show that its core semantic insight—
coordination-freedom coincides with monotonicity—follows directly from our
history-based framework under a natural choice of observations and outcome order.

\subsubsection{Relational Transducers and Histories}

We adopt the relational transducer model of
Ameloot et al.~\cite{ameloot2013relational}.
A transducer execution consists of a collection of nodes, each executing the same
logic program, communicating by asynchronous message passing.

A \emph{history} records
(i) the application of rules at nodes,
(ii) message send and receive events, and
(iii) external input facts injected at nodes.
The happens-before relation captures rule dependencies within a node and message
causality across nodes, as in Section~\ref{sec:obs-consistency}.
We impose no fairness or delivery guarantees: messages may be delayed or lost, and
rule application may cease at any node.

\subsubsection{Observations and Outcome Order}

To model eventual consistency, we take outcomes to be \emph{eventual output
  relations}.
Formally, let $O$ be the set of finite or infinite relational instances over the
output schema of the program.
For a history $H$, define $\Poss(H)$ to be the set of output relations that remain
compatible with $H$—that is, relations that are not ruled out by any causally
admissible extension of $H$ under the program semantics.

We equip $O$ with the outcome order $\Ord$ given by set inclusion.
Intuitively, $R_1 \Ord R_2$ means that $R_2$ is a refinement of $R_1$ obtained by
adding facts.
This choice reflects the standard CALM interpretation of eventual outputs: once a
fact appears, it is never retracted.

\subsubsection{Specifications}

A logic program induces a specification $\Spec = (\Poss, \Obs, \Ord)$,
where $\Poss$ and $\Ord$ are as defined above.
For any history $H$, $\Obs(H)$ is the set of output
relations given by the least fixpoint of the program over the input facts
contained in $H$.
That is, $\Obs(H)$ contains the semantically correct relations derivable
given the information available at $H$.
Correctness of an implementation requires that any outcome it exposes at history
$H$ belong to $\Obs(H)$.

Under this interpretation, a specification is \emph{monotone} in our sense if and
only if extending a history cannot invalidate a previously observable output
fact—i.e., every output relation remains extendable by set inclusion along every
causally consistent extension.

\subsubsection{Equivalence with CALM}

We now relate specification monotonicity to program monotonicity.

\begin{lemma}
  A relational transducer program is monotone with respect to set inclusion on input
  facts if and only if the induced specification $\Spec$ is monotone with respect to
  history extension under the outcome order $(O,\subseteq)$.
\end{lemma}

\begin{proof}[Proof sketch]
  If the program is monotone, adding input facts or delaying messages can only add
  derived output facts, never retract them.
  Thus any output relation admissible at a prefix history remains extendable under
  set inclusion at all causal extensions, establishing specification monotonicity.

  Conversely, if the program is non-monotone, there exists a history prefix at which
  some output relation is admissible, but a causally admissible extension (e.g., the
  arrival of an additional input fact or message) invalidates that output.
  This yields a history pair $H_1 \hext H_2$ witnessing non-monotonicity of $\Spec$.
\end{proof}

Applying the Coordination Criterion then yields the CALM equivalence.

\begin{theorem}[CALM, via the Coordination Criterion]
  A relational transducer program admits a coordination-free, eventually consistent
  distributed evaluation if and only if it is monotone with respect to set inclusion
  on input facts.
\end{theorem}

\subsubsection{Relation to CALM and Strict Generalization}

In the CALM setting, program monotonicity and specification monotonicity coincide
because observability is taken to coincide with eventual outputs ordered by inclusion.
Our framework makes clear that this coincidence is a modeling choice, not a
necessity.

More generally, a specification may admit coordination-free implementations even
when internal rules are non-monotone, provided that the observable outcomes
themselves are monotone. It is straightforward to construct such examples by instantiating a transducer with a monotone logic program $P_1$ whose outputs are made observable, and adding rules from a non-monotone logic program $P_2$ whose outputs are not made observable by the transducer, where $P_1$ makes no reference to the relations defined in $P_2$. The \emph{program} $P_1 \cup P_2$ is non-monotone, but the \emph{specification} induced by the transducer is monotone, since only the outputs of $P_1$ are observable.
This separation between internal definitions and observable commitments is
invisible in CALM’s program-centric formulation but central to the Coordination
Criterion.

Thus CALM arises as a clean special case of a more general semantic principle:
coordination is required exactly when observable commitments are non-monotone with
respect to causal extension.

\subsection{Snapshots}

Snapshot objects provide a sharp boundary case for the Coordination Criterion.
Global snapshot and atomic snapshot expose similar interfaces, but differ
fundamentally in how admissible outcomes behave under history extension.

\parhead{$\SpecIt$ sketch.}
Histories are executions of a shared-memory system with read and write events on
shared variables.
Outcomes are snapshot results, recording the values of all variables at a single
logical point.

For global snapshot,
$
  \Poss(H) = \Obs(H)
$
is the set of all downward-closed cuts of the happens-before relation realizable
by some causal extension of \(H\).
Here, the outcome order $\Ord_{\mathit{global}}$ is cut extension.

For atomic snapshot, \(\Poss(H)\) is the set of snapshot results realizable under
\emph{some} linearization extending \(H\).
The observability function \(\Obs(H)\) selects snapshot results that the
specification treats as correct at \(H\), each committing to a particular
linearization point.
By contrast, the outcome order $\Ord_{\mathit{atomic}}$ refines linearization-point commitments.

\parhead{Global snapshot.}
A global snapshot outcome corresponds to a downward-closed cut of
happens-before.
Extending a history can only add events after such a cut, never invalidate it.
Accordingly, no admissible outcome is invalidated by any causally admissible extension.
The specification is monotone and admits coordination-free implementations.

\parhead{Atomic snapshot.}
In contrast to global snapshot, atomic snapshot commits to a total order rather
than a cut.
Atomic snapshot strengthens the specification by requiring each snapshot to
correspond to a single linearization point.
At a prefix history $H$, multiple linearizations of concurrent events may remain
possible.
Thus $\Poss(H)$ may contain several snapshot results, but observing any one of
them fixes a particular ordering of those events.

Consider a prefix history $H$ in which a snapshot is concurrent with a write.
At $H$, $\Poss(H)$ includes outcomes corresponding to different linearizations of
the snapshot relative to the write.
Under the linearization-refinement order, these outcomes are incompatible, since
each commits to a distinct total order.
Because causality permits extensions that realize either ordering, committing to
one at $H$ rules out correctness along the other.

Thus atomic snapshot admits observable outcomes at a prefix history that cannot be
preserved under all causally admissible extensions, making coordination intrinsic.

\subsection{$k$-set Agreement}
\label{app:agreement-extensions}

$k$-set agreement generalizes consensus by permitting up to $k$ distinct decision
values among participating processes.
From the perspective of the Coordination Criterion, this relaxation weakens the
safety condition but not the underlying structure.
This example shows that weakening safety constraints does not restore monotonicity.

\parhead{$\SpecIt$ sketch.}
Histories record invocations and decisions by processes.
Observable outcomes map each deciding process to its chosen value, subject to the
constraint that at most $k$ distinct values appear.
The outcome order is pointwise extension on partial decision maps.

\parhead{Non-monotonicity.}
At a prefix history $H_1$, multiple distinct decision maps—each respecting the
$k$-value bound—may remain observable.
However, for any $k \ge 1$, there exist causally admissible extensions $H_2 \hext H_1$
that rule out some of these maps, yielding outcomes at $H_1$ with no
$\Ord$-extension in $\Obs(H_2)$.
Thus the specification admits future-inconsistent observable outcomes.

This recovers the classical impossibility of wait-free $k$-set agreement in
asynchronous systems~\cite{saks2000set} as a direct consequence of
non-monotonicity.

The same decision-map observability and outcome order yield witnesses of
non-monotonicity for a wide class of agreement tasks studied in distributed
computability, including multi-valued and Byzantine agreement variants.

\subsection{Strong Renaming}
\label{app:strong-renaming}
\begin{corollary}[Strong Renaming]
  \label{cor:renaming}
  The strong renaming task~\cite{herlihy1999topological} is non-monotone with
  respect to history extension and therefore intrinsically requires coordination:
  the set of admissible name assignments can shrink as participants or concurrency
  increase.
\end{corollary}

\begin{proof}[Proof sketch]
  In the strong renaming task, each participating process must acquire a unique
  name from a namespace whose size depends on the number of participating
  processes, so correctness depends on the maximal concurrency of the
  execution.
  Because the allowed name space depends on the participating set, extending a
  history by adding participants or increasing overlap can shrink the set of
  admissible name assignments.
  Classical renaming results (e.g., in the wait-free hierarchy and topological
  computability literature~\cite{herlihy1991waitfree,herlihy1999topological})
  exhibit histories $H_1 \hext H_2$ in which a name assignment satisfying strong
  renaming at $H_1$ admits no extension satisfying strong renaming at $H_2$ while
  preserving the original names.
  Such non-monotonicity implies, by the Coordination Criterion, that strong
  renaming intrinsically requires coordination, independently of the particular
  wait-freedom or solvability assumptions made in classical hierarchy results.
\end{proof}
Strong renaming thus isolates a distinct source of non-monotonicity: admissibility
depends on the eventual set of participating processes.
Unlike snapshots or registers, the difficulty is not how events are interpreted,
but which processes ultimately participate.
This membership sensitivity reappears in consensus, where it interacts
with value exposure.

\subsection{Transactional Isolation Levels}
\label{app:isolation}

Classical work on transactions distinguishes a spectrum of isolation levels,
often characterized by which anomaly patterns they forbid on transactional
executions~\cite{berenson1995critique}.
Subsequent work, most notably that of Bailis et al., identified a boundary
between isolation levels that admit highly available implementations under
asynchrony and partitions and those that intrinsically require
coordination~\cite{bailis2013hat}.
We recover this boundary semantically via monotonicity.

\parhead{Histories and observations.}
We model transactional executions as histories whose events include transaction
invocations, read and write events on shared objects, and commit or abort
decisions.
We restrict attention to committed transactions, treating aborts as producing
no observable effects.

An \emph{outcome} is a finite set of atomic facts of the form
\[
  \mathsf{commit}(T)
  \quad\text{and}\quad
  \mathsf{read}(T,x,v),
\]
where $\mathsf{commit}(T)$ records that transaction $T$ has committed, and
$\mathsf{read}(T,x,v)$ records that transaction $T$, upon committing, returned
value $v$ for a read of location $x$.
Each read fact is associated with a specific transaction and location.


Define $\Poss(H)$ to be the singleton set containing exactly the outcome consisting
of all such facts induced by the committed transactions in $H$.
This reflects that transactional histories deterministically determine which
commit and read facts have already occurred; uncertainty arises only from which
additional transactions may commit in future extensions.

\parhead{Outcome order.}
We order outcomes by set inclusion:
\[
  o_1 \Ord o_2 \quad\text{iff}\quad o_1 \subseteq o_2.
\]
Under this order, one outcome refines another precisely by recording additional
observable facts, corresponding to additional committed transactions or
additional read results.

\parhead{Isolation levels as specifications.}
An isolation level $L$ is modeled as a specification
\[
  \Spec_L = (\Poss, \Obs_L, \Ord),
\]
where $\Obs_L(H)$ consists of those outcomes in $\Poss(H)$ that satisfy
the constraints imposed by $L$.
That is, $\Obs_L(H) \subseteq \Poss(H)$, and an outcome is treated as observable at
$H$ exactly when it lies in $\Obs_L(H)$.
These constraints may forbid particular combinations of read and commit facts,
corresponding to classical anomalies such as dirty reads, lost updates, or
write skew.

Crucially, isolation levels differ in whether the anomalies they forbid are
\emph{prefix-closed} with respect to history extension—that is, whether forbidding
an anomaly can ever invalidate a previously observable outcome.
An anomaly is prefix-closed if, once it appears in an outcome, no history extension
can eliminate it without producing an outcome that fails to extend the original
one under the outcome order.

\parhead{Monotone isolation levels.}
Isolation levels such as read uncommitted, read committed, and session guarantees
in the sense of Terry et al.~\cite{terry1994session} forbid only prefix-closed
anomalies.
For these levels, if $o \in \Obs_L(H)$, then for any extension $H' \hext H$ there
exists $o' \in \Obs_L(H')$ with $o \subseteq o'$:
extending the history may add further committed transactions and read facts, but
cannot invalidate existing ones.
Accordingly, the induced specification $\Spec_L$ is monotone with respect to
history extension.
By the Coordination Criterion, these isolation levels admit coordination-free
implementations.

\parhead{Non-monotone isolation levels.}
By contrast, isolation levels that require a global serialization or snapshot
order---including serializable isolation and snapshot isolation---are
non-monotone.
For such levels, there exist histories $H_1 \hext H_2$ and an outcome
$o_1 \in \Obs_L(H_1)$ such that no outcome in $\Obs_L(H_2)$ extends $o_1$ under
$\Ord$.
Intuitively, an outcome in $\Obs_L(H_1)$ for a partial execution
may become incompatible once the history is extended with additional committed
transactions that constrain the required global order, yielding a semantic
witness of non-monotonicity.
Any implementation that preserves correctness under these specifications must
therefore exclude some causally consistent executions and introduce
coordination.

For exposition, we provide a concrete example for snapshot isolation;
analogous examples exist for serializability and other non-monotone levels.
\begin{example}[Non-Monotonicity under Snapshot Isolation]
  \label{ex:si-nonmonotone}
  Consider two transactions $T_1$ and $T_2$ operating on variables $x$ and $y$,
  both initially $0$.
  Transaction $T_1$ reads $x$ and writes $y := 1$; transaction $T_2$ reads $y$ and
  writes $x := 1$.

  Let $H_1$ be a history in which $T_1$ has executed and committed, while $T_2$
  has not yet decided.
  The observation
  \[
    o_1 = \{\mathsf{commit}(T_1), \mathsf{read}(T_1,x,0)\}
  \]
  is admissible under snapshot isolation: $T_1$ can read from an initial snapshot
  and commit.

  Now extend $H_1$ to a history $H_2$ by adding a committing execution of $T_2$ in
  which $T_2$ reads $y = 0$.
  Any observation $o_2$ for $H_2$ must include both read results:
  \[
    o_2 = o_1 \cup \{\mathsf{commit}(T_2), \mathsf{read}(T_2,y,0)\}.
  \]
  However, no such $o_2$ is admissible under snapshot isolation.
  The read of $x=0$ by $T_1$ requires $T_1$'s snapshot to precede $T_2$'s write to
  $x$, while the read of $y=0$ by $T_2$ requires $T_2$'s snapshot to precede
  $T_1$'s write to $y$, yielding a cyclic snapshot order.

  Thus there exist histories $H_1 \hext H_2$ and an observation $o_1 \in \Obs(H_1)$
  such that no observation in $\Obs(H_2)$ extends $o_1$.
  The snapshot isolation specification is therefore non-monotone with respect to
  history extension.
\end{example}

\parhead{Discussion.}
This example isolates the semantic distinction underlying prior results on highly
available transactions.
Coordination-freedom is determined neither by the use of transactions nor by
progress guarantees, but by whether an isolation level’s correctness constraints
are monotone under history extension.

Isolation levels such as read committed or session guarantees impose only
prefix-closed constraints: for any $o \in \Obs_L(H_1)$, there is for each causally
consistent extension $H_1 \hext H_2$ some $o' \in \Obs_L(H_2)$ consistent with $o$.
By contrast, stronger levels—including snapshot isolation and serializability—
admit histories for which some $o \in \Obs_L(H_1)$ is inconsistent with every
$o' \in \Obs_L(H_2)$ for some causally consistent extension $H_1 \hext H_2$.
Preserving consistency in such cases requires coordination to resolve these
incompatible observations to a single outcome.

Viewed imperatively, this corresponds to the familiar distinction that highly
available isolation levels permit transactions to commit independently, whereas
stronger isolation levels require commitments that are mutually constraining.

\subsection{Invariant Confluence}

Coordination-free execution has also been studied for application-level
invariants.
Bailis et al.\ introduce \emph{invariant confluence} ($I$-confluence) and show
that some invariants can be preserved without coordination in replicated
databases, while others fundamentally require it~\cite{bailis2014coordination}.

We model such systems as histories whose events include transaction invocations,
replica-local updates, and merge operations.

An \emph{outcome} represents semantic uncertainty about the database state after a
history.
Formally, the outcome domain $O$ consists of sets of database states, where an
outcome $o \in O$ represents the set of states that may be reachable.
We order outcomes by set inclusion:
\[
  o_1 \Ord o_2 \quad\text{iff}\quad o_1 \subseteq o_2,
\]
so that refinement corresponds to monotonically ruling out states.

The possibility function $\Poss(H)$ consists of all outcomes representing sets of
database states that remain reachable under some causally admissible extension of history $H$
in the asynchronous model.

Given an application invariant $I$, the specification
\[
  \Spec_I = (\Poss, \Obs_I, \Ord)
\]
defines $\Obs_I(H)$ to be those outcomes $o \in \Poss(H)$ in which every state
satisfies the invariant:
\[
  \Obs_I(H) = \{\, o \in \Poss(H) \mid \forall s \in o.\; I(s) \,\}.
\]

If $I$ is $I$-confluent, then extending a history with additional locally valid
transactions and merges cannot introduce a reachable state that violates $I$.
Equivalently, for all histories $H_1 \hext H_2$ and all $o \in \Obs_I(H_1)$, there
exists $o' \in \Obs_I(H_2)$ such that $o \Ord o'$.
Thus the specification $\Spec_I$ is monotone with respect to history extension and,
by the Coordination Criterion, admits coordination-free implementations.

If $I$ is not $I$-confluent, there exist histories $H_1 \hext H_2$ and an outcome
$o \in \Obs_I(H_1)$ such that no outcome in $\Obs_I(H_2)$ extends $o$ under $\Ord$.
In this case, $\Spec_I$ is non-monotone and enforcing $I$ necessarily requires
coordination.

\parhead{Discussion.}
At first glance, this correspondence may appear definitional: $I$-confluence is
defined so as to permit coordination-free execution.
The contribution of the Coordination Criterion is to locate this property at the
level of \emph{specifications} rather than merge semantics or replica behavior.
Invariant confluence emerges here as a special case of a general semantic
boundary: application invariants admit coordination-free enforcement precisely
when their observable outcomes are monotone under history extension.
This reframes $I$-confluence not as a separate theory of coordination, but as
another instance of the same monotonicity principle governing registers,
snapshots, agreement, and transactional isolation\footnote.

%% -------------------------------------------------------------
\section{Proof of the Coordination Criterion}
\label{app:coordination-criterion-proof}
%% -------------------------------------------------------------

For completeness we restate and fully prove Theorem~\ref{thm:coordination-criterion}.

\begin{theorem}[Coordination Criterion, restated]
  A distributed specification admits a coordination-free
  implementation if and only if it is monotone with respect to history
  extension under the chosen outcome order $\Ord$.

  This equivalence is proved under the asynchronous message-passing model of
  Section~\ref{sec:obs-consistency}, in which histories may be finite or infinite,
  messages may be delayed or lost, and crashes are modeled as processes that take
  no further steps.
  We assume that $\Ord$ is a partial order on observable outcomes and that each
  specification $\Spec = (\Poss, \Obs, \Ord)$ has a total admissibility function
  $\Obs : \Hist \rightarrow \mathcal{P}(O)$ (it is defined on every history in $\Hist$).
  No progress or fairness assumptions (such as termination or wait-freedom) are
  required for the theorem itself.
\end{theorem}

\begin{proof}
  We have to prove both directions of the equivalence.
  Throughout the proof, when we speak of an outcome exposed by an implementation
  at a history $H$, we mean an outcome that the implementation may expose at $H$
  and that is required by correctness to lie in $\Obs(H)$.

  \vspace{0.5em}
  \noindent\textsc{\emph{Sufficiency.}}
  Fix a specification $\Spec = (\Poss, \Obs, \Ord)$ that is monotone with respect to $\hext$ and the
  chosen outcome order $\Ord$.
  To prove sufficiency, we must exhibit an implementation $I_\Spec$ that is
  coordination-free in the sense of the preceding definition: for every
  admissible input history $H_{\mathit{in}}$, its realizable histories satisfy
  that, for all $H \in \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$, the implementation
  chooses some outcome $o(H) \in \Obs(H)$ and
  $\mathcal{R}_{I_\Spec}(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$.

  \emph{Construction of $I_\Spec$.}
  We give an idealized operational model in which the implementation's state
  records the current history and the implementation does not introduce any
  additional restrictions on admissible executions beyond causal consistency.
  This construction is purely semantic and existential: it serves only to witness
  coordination-freedom and is not intended to be realizable by any finite-state or
  practical protocol.
  For each admissible input history $H_{\mathit{in}}$, consider a labeled
  transition system whose configurations are histories $H \in \Hist$ with
  $H_{\mathit{in}} \hext H$.
  The initial configuration is $H_{\mathit{in}}$.
  There is a transition $H \rightarrow_I H'$ whenever all of the following hold:
  (i) $H \hext H'$; (ii) $H'$ extends $H$ by a single event (i.e., if
  $H = (E,\rightarrow)$ and $H' = (E',\rightarrow')$, then
  $E' = E \cup \{e\}$ for some event $e$); and (iii) $H'$ respects the
  asynchronous message-passing constraints of Section~\ref{sec:obs-consistency}
  (in particular, it extends the local program order and send/receive edges and
  may delay or drop messages).
  Intuitively, $I_\Spec$ maintains the exact history generated so far and
  allows any single-event causally admissible extension.
  For each history $H$, the implementation nondeterministically chooses
  some outcome $o_H \in \Obs(H)$ to expose.
  Because $\Obs(H) \subseteq \Poss(H)$ by definition of a specification,
  every exposed outcome is causally possible at $H$.
  Monotonicity of $\Spec$ ensures that every such choice remains $\Ord$-compatible
  with at least one outcome in $\Obs(H')$ for every extension $H \hext H'$.

  \emph{Correctness.}
  By construction, for every admissible input history $H_{\mathit{in}}$ and every
  realizable history $H \in \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$, the
  implementation reports some outcome $o_H \in \Obs(H)$.
  Thus clause~(i) of coordination-freedom holds.

  \emph{No additional pruning.}
  Fix an admissible input history $H_{\mathit{in}}$.
  By construction, every run of $I_\Spec$ from $H_{\mathit{in}}$ produces a
  chain of histories
  \[
    H_{\mathit{in}} = H_0 \hext H_1 \hext H_2 \hext \cdots
  \]
  in which each step adds a single event consistent with the asynchronous
  semantics.
  The limit of this chain (for a finite or infinite run) is a history
  $H \in \Hist$ with $H_{\mathit{in}} \hext H$ that respects causality, so
  $H \in \mathcal{A}(H_{\mathit{in}})$.
  Thus every realizable history is asynchronously admissible and
  $\mathcal{R}_{I_\Spec}(H_{\mathit{in}}) \subseteq \mathcal{A}(H_{\mathit{in}})$.

  For the converse inclusion, take any history $H \in \mathcal{A}(H_{\mathit{in}})$.
  Because $H$'s happens-before relation is a partial order and its event set is
  finite or countably infinite, there exists a linear extension (topological
  ordering) $e_1,e_2,\ldots$ of the events of $H$ restricted to those not already
  in $H_{\mathit{in}}$ such that every predecessor of $e_k$ in $H$ appears among
  $\{e_1,\ldots,e_{k-1}\}$.
  We construct a run of $I_\Spec$ that realizes $H$ by induction on $k$.
  Base: the initial configuration is $H_{\mathit{in}}$.
  Inductive step: suppose the current configuration is some history $H^{(k-1)}$
  with $H_{\mathit{in}} \hext H^{(k-1)} \hext H$ containing exactly the events
  $e_1,\ldots,e_{k-1}$ in addition to those of $H_{\mathit{in}}$.
  By the choice of linear extension, all predecessors of $e_k$ in $H$ are already
  in $H^{(k-1)}$, so adding $e_k$ yields a history $H^{(k)}$ with
  $H^{(k-1)} \hext H^{(k)} \hext H$ that respects the asynchronous constraints.
  By the transition rule, there is a step $H^{(k-1)} \rightarrow_I H^{(k)}$.
  Thus by induction we obtain a (finite or infinite) run whose limit history is
  exactly $H$.
  Hence $H \in \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$, so
  $\mathcal{A}(H_{\mathit{in}}) \subseteq \mathcal{R}_{I_\Spec}(H_{\mathit{in}})$.

  Combining both inclusions, we obtain
  $\mathcal{R}_{I_\Spec}(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$ for
  every admissible input history $H_{\mathit{in}}$.
  Together with correctness, this shows that $I_\Spec$ is coordination-free for
  $\Spec$.

  \begin{remark}[On the idealized sufficiency construction]
    The implementation $I_\Spec$ constructed in the sufficiency proof is deliberately
    idealized and semantic.
    It should not be read as a protocol sketch or as asserting implementability in any
    realistic computational model.
    Rather, it serves as an \emph{existence witness}: it demonstrates that when a
    specification is monotone, there is no \emph{semantic obstruction} to realizing all
    causally admissible histories while remaining observationally correct.
    The construction isolates coordination as a purely semantic phenomenon—arising
    only from the need to exclude causally consistent executions—and separates this
    concern from issues of computability, state representation, or protocol design,
    which are orthogonal to the Coordination Criterion.
  \end{remark}

  \medskip
  \noindent\textsc{\emph{Necessity.}}
  Conversely, suppose $\Spec$ is non-monotone.
  Then there exists a history $H_1$ and an outcome $o_1 \in \Obs(H_1)$ that is
  \emph{future-inconsistent}: for some extension $H_2 \hextback H_1$, $o_1$ contradicts
  every outcome in $\Obs(H_2)$ under $\Ord$.

  Because $H_1 \hext H_2$, we may choose an admissible input history
  $H_{\mathit{in}}$ that contains exactly the external input events of $H_1$.
  Both $H_1$ and $H_2$ are causally consistent extensions of $H_{\mathit{in}}$,
  so $H_1,H_2 \in \mathcal{A}(H_{\mathit{in}})$.

  Assume for contradiction that there exists an implementation $I$ that is both
  correct for $\Spec$ and coordination-free.
  By coordination-freedom,
  $\mathcal{R}_I(H_{\mathit{in}}) = \mathcal{A}(H_{\mathit{in}})$, so in particular
  $H_1,H_2 \in \mathcal{R}_I(H_{\mathit{in}})$.

  Fix a run of $I$ from $H_{\mathit{in}}$ whose resulting history is $H_2$, and
  consider the prefix of this run obtained by stopping immediately after the last
  event of $H_1$.
  This prefix is itself an admissible run of $I$ (our asynchronous model imposes
  no fairness obligations), and its history is exactly $H_1$.
  Thus there exist two runs of $I$ from the same input history $H_{\mathit{in}}$
  that coincide up to history $H_1$ but whose admissible
  extensions realize $H_1$ and $H_2$ respectively.

  Because $o_1$ is future-inconsistent, there is no outcome compatible with both
  $H_1$ and its extension $H_2$ under $\Ord$.
  Because correctness requires $\Expose_I(H_1) \subseteq \Obs(H_1)$, and
  $\Obs(H_1)$ contains at least one admissible outcome, the implementation must
  commit to some outcome in $\Obs(H_1)$ along any run realizing $H_1$.
  Any such choice will be incompatible with every outcome in $\Obs(H_2)$ along the
  admissible extension to $H_2$.

  To remain correct on all admissible runs from $H_{\mathit{in}}$, $I$ must therefore
  exclude at least one of the causally consistent extensions $H_1$ or $H_2$.
  Equivalently,
  $\mathcal{R}_I(H_{\mathit{in}}) \subsetneq \mathcal{A}(H_{\mathit{in}})$,
  contradicting coordination-freedom.
  Hence no implementation can be both correct for a non-monotone specification and
  coordination-free.

  \begin{remark}[On the necessity argument]
    The necessity direction does not rely on any assumptions about how or when an
    implementation exposes observations, nor on liveness, fairness, or output
    timing.
    It uses only the fact that a correct implementation must associate \emph{some}
    outcome in $\Obs(H)$ with every history it realizes.
    When a specification is non-monotone, this requirement alone forces a conflict:
    any outcome in $\Obs(H_1)$ at a prefix history may be rendered incompatible with
    all outcomes in $\Obs(H_2)$ required by some causally admissible extension.
    Thus the impossibility arises from semantic incompatibility under history
    extension, not from operational constraints or protocol-level limitations.
  \end{remark}

  \parhead{Relation to FLP-style impossibility results.}
  The necessity direction of the Coordination Criterion has a close structural
  affinity with classical FLP-style impossibility arguments~\cite{fischer1985impossibility}.
  In both cases, the core obstruction is not a lack of progress or fairness, but
  the existence of two causally admissible extensions of the same prefix history
  that admit no outcome compatible with both.
  FLP exhibits this phenomenon operationally, by constructing executions in which
  any attempt to decide eventually leads to a contradiction under asynchrony.
  Here, we isolate the same obstruction semantically: non-monotonicity witnesses
  a prefix at which every outcome in $\Obs(H_1)$ would be invalidated by some
  causally consistent extension.
  The Coordination Criterion can thus be read as a semantic generalization of the
  FLP insight, characterizing exactly when such contradictions are unavoidable,
  independently of any particular task or protocol.
  Conversely, classical wait-free tasks like snapshots and CRDT-style objects
  fit the monotone side of the criterion: their specifications ensure that every
  locally observable outcome remains compatible with all causally consistent
  extensions, explaining why they admit coordination-free implementations despite
  unbounded delay.
\end{proof}

% ================================================================
\section{Minimality of the Coordination Criterion}
\label{app:minimality}
% ================================================================

This appendix clarifies the sense in which the Coordination Criterion is
\emph{minimal}.
The result does not assert that monotonicity is the only reasonable semantic
condition one might study.
Rather, it shows that monotonicity is unavoidable at the semantic level:
any specification that admits a coordination-free implementation necessarily
induces a monotone structure on its observable outcomes under an appropriate
outcome order.
In this sense, monotonicity is not a modeling choice, but an intrinsic property
of coordination-free behavior.

\begin{proposition}[Semantic Minimality]
  Let $\mathcal{C}$ be any class of distributed specifications such that every
  $\Spec \in \mathcal{C}$ admits a coordination-free consistent implementation
  in the asynchronous model.
  Then for each $\Spec \in \mathcal{C}$ there exists an outcome order $\Ord$,
  induced by the implementation’s observable compatibility—that is, by which
  outcomes can arise together along some causally admissible execution—under
  which $\Spec$ is monotone with respect to history extension.
\end{proposition}

This proposition makes the minimality claim precise.
Any semantic criterion sufficient to guarantee coordination-freedom must already
entail monotonicity under some outcome order derived from observable behavior.
Monotonicity is therefore not an added assumption, but the weakest semantic
structure that coordination-free implementations inevitably exhibit.

\begin{proof}[Proof sketch]
  Fix a specification $\Spec = (\Poss,\Obs,\Ord)$ that admits a coordination-free
  implementation $I$.
  By definition of coordination-freedom, for every admissible input history
  $H_{\mathit{in}}$, the implementation realizes exactly the set
  $\mathcal{A}(H_{\mathit{in}})$ of causally admissible extensions.

  For each history $H$, let $\Obs_I(H)$ denote the set of outcomes that $I$ may
  expose at $H$ across its admissible executions.
  Observational correctness ensures $\Obs_I(H) \subseteq \Obs(H)$ for all $H$.

  Because $I$ does not exclude any causally admissible extension, extending a
  history cannot invalidate all future realizations of an exposed outcome:
  any outcome exposed at $H_1$ remains realizable along some extension to $H_2$.

  Ordering outcomes by this extension relation yields an outcome order under which
  $\Spec$ is monotone with respect to history extension.
  This derived outcome order reflects semantic compatibility induced by the
  implementation itself: two outcomes are ordered precisely when the
  implementation can realize them along a common causal extension.
\end{proof}

\parhead{Discussion.}
The construction above is intentionally coarse and serves only to establish
semantic minimality.
It shows that any semantic criterion sufficient to guarantee coordination-freedom
must already induce monotonicity under some outcome order derived from observable
behavior.
Refinements therefore arise from changing the semantic interface, not from
weakening the Coordination Criterion itself.

\section{Extended Related Work and Connections}
\label{sec:extended-related-work}
Here we highlight connections to prior work that were not discussed in the main text.

\parhead{CALM Generalizations.}
The Coordination Criterion is closest in spirit to the CALM line of work, which
connects coordination-freedom to monotonicity in declarative distributed
computation.
This literature—including relational transducers and logic-based models—studies
coordination relative to semantic domains and execution assumptions that are
stronger than those of a canonical asynchronous system
\cite{hellerstein2010declarative,ameloot2013relational,ameloot2015weaker}.

The most recent work in this line, by Baccaert and Ketsman~\cite{baccaert2026spectrum},
moves beyond language-specific analyses by modeling distributed computation as
semantic mappings between relations and parameterizing coordination-freedom by a
family of \emph{system constraints}.
These constraints restrict which executions are admissible, yielding a spectrum
of monotonicity conditions under increasingly strong assumptions.
While this advances the CALM program toward a more semantic treatment of
admissibility, it remains framed within a relation-to-relation computational model
with fixed input and output structures.

Li and Lee~\cite{li2025coordinationfree} pursue a complementary abstraction. They formulate coordination-freedom at the level of ordered input–output problems and parameterize correctness by an explicit refinement order on outputs.
Their model abstracts away from programming language details and studies robustness under partitioning of an input domain. In contrast, we take Lamport histories themselves as the semantic domain and characterize coordination-freedom by requiring implementations to realize all causally admissible history extensions. The two approaches share a semantic goal, but differ in the underlying notion of extension: input-set inclusion versus happens-before.

% By contrast, our work makes no assumptions beyond standard causality.
% We take Lamport histories as the semantic domain and define specifications
% abstractly via admissible histories and observable outcomes ordered by refinement.
% This semantically minimal formulation accommodates arbitrary input and output
% structures and any program or machine model, yielding a general diagnostic
% criterion for when coordination is \emph{intrinsic to the specification itself}.
% Because it relies only on causality and semantic refinement—rather than on program
% semantics, constraint regimes, or execution assumptions—the Coordination Criterion
% applies directly to the full range of classical distributed objects, tasks, and
% consistency conditions studied in this paper, without translation into a
% particular language, logic, or replicated-object formalism
% (cf.~Section~\ref{sec:applications} and
% Appendix~\ref{sec:additional-applications}).

We also note a connection to Gallifrey~\cite{milano2019tour}, which makes
monotonicity explicit in the type system by requiring programmers to specify the
order with respect to which values evolve.
This design choice influenced our decision to reify observability and outcome
order as first-class components of a specification.

\parhead{Transactional and Weak Consistency Semantics.}
History- and anomaly-based characterizations of transactional isolation levels
and weak consistency models
\cite{adya2000generalized,berenson1995critique,crooks2017seeing}
analyze which behaviors client programs can observe under different guarantees.
Given any such model as a specification in our sense, monotonicity of its
observable outcomes predicts whether it admits coordination-free
implementations; Appendix~\ref{sec:additional-applications} applies this lens
to the HAT versus non-HAT isolation levels and to invariant-preserving
replicated transactions.

\parhead{Programming Languages for Coordination-Free Distributed Systems.}

A parallel line of work in programming languages has sought to make
coordination requirements explicit or avoidable through language design.
Rather than treating coordination as an emergent property of low-level
protocols, these systems structure programs so that safe distributed
execution follows from semantic restrictions on state, effects, or time.

Gallifrey~\cite{milano2019tour} is a functional language for distributed
programming that makes temporal structure explicit in the type system.
Programs are required to specify the order with respect to which values evolve,
making monotonicity a typed semantic obligation rather than an implicit property
of an implementation.
From our perspective, this corresponds directly to making the outcome order
explicit: only values that are stable under all causal extensions relative to the
chosen order may be exposed.
Gallifrey thus enforces observational stability by construction and influenced our
decision to reify observability and outcome order as first-class components of a
specification.

Flo~\cite{laddad2024flo} takes a complementary approach through reactive
dataflow.
Programs define continuously evolving signals whose values may be refined as new
inputs and events arrive.
The language enforces monotonicity and inflationarity constraints on observable
state, ensuring that outputs may grow or refine but are never semantically
retracted.
Although Flo is presented operationally as a dataflow system, its guarantees
align closely with monotone specifications in our sense: once an outcome becomes
observable, it remains compatible with all future observations.

Earlier systems explored similar ideas in more operational or
domain-specific forms.
Dedalus~\cite{alvaro2010dedalus} introduced a temporal logic programming model
that makes asynchrony explicit by separating deductive, inductive, and
asynchronous rules.
This separation exposed the semantic role of time and causality in distributed
programs and directly motivated the CALM conjecture.
Bloom~\cite{alvaro2011bloom} built on Dedalus to provide a practical programming
model in which monotone programs admit coordination-free execution, while
non-monotone constructs require explicit coordination mechanisms.

Lasp~\cite{meiklejohn2015lasp} represents a different point in the design space,
centered on replicated data types rather than logic or dataflow.
By restricting shared state to join-semilattices and updates to inflationary
operations, Lasp ensures that replicas converge without coordination.
In semantic terms, Lasp enforces monotonicity by construction at the level of
observable outcomes, guaranteeing that all exposed results remain compatible
under causal extension.

\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

\end{document}
